{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### python test class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config files\n",
    "\n",
    "Provide option to input config files, in the form I want to get, if they don't provide any, you give/use default values. \n",
    ".txt format\n",
    "\n",
    "Describe it in the documentation how it should look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openTSNE import TSNEEmbedding\n",
    "from openTSNE import initialization\n",
    "from openTSNE.callbacks import ErrorLogger\n",
    "\n",
    "#import utils\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "x, y = iris[\"data\"], iris[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set contains 150 samples with 4 features\n"
     ]
    }
   ],
   "source": [
    "print(\"Data set contains %d samples with %d features\" % x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 training samples\n",
      "50 test samples\n"
     ]
    }
   ],
   "source": [
    "print(\"%d training samples\" % x_train.shape[0])\n",
    "print(\"%d test samples\" % x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a t-SNE embedding\n",
    "\n",
    "Like in the *simple_usage* notebook, we will run the standard t-SNE optimization.\n",
    "\n",
    "This example shows the standard t-SNE optimization. Much can be done in order to better preserve global structure and improve embedding quality. Please refer to the *preserving_global_structure* notebook for some examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Compute the affinities between data points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNIndex_Elements:\n",
    "    def __init__(self, metric, metric_params=None, n_jobs=1, random_state=None):\n",
    "        self.index = None\n",
    "        self.metric = metric\n",
    "        self.metric_params = metric_params\n",
    "        self.n_jobs = n_jobs\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def build(self, data):\n",
    "        \"\"\"Build the index so we can query nearest neighbors.\"\"\"\n",
    "\n",
    "    def query_train(self, data, k):\n",
    "        \"\"\"Query the index for the points used to build index.\"\"\"\n",
    "\n",
    "    def query(self, query, k):\n",
    "        \"\"\"Query the index with new points.\"\"\"\n",
    "\n",
    "    def check_metric(self, metric):\n",
    "        \"\"\"Check that the metric is supported by the KNNIndex instance.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import multi_nearest_neighbors.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NearPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xc but this version of numpy is 0xb",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xc but this version of numpy is 0xb"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-be971038471f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnearpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEngine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnearpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhashes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomBinaryProjections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nearpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnearpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEngine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nearpy/engine.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnearpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhashes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomBinaryProjections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnearpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhashes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCABinaryProjections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnearpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhashes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomBinaryProjectionTree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nearpy/hashes/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnearpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhashes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlshash\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLSHash\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnearpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhashes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandombinaryprojections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomBinaryProjections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnearpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhashes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandomdiscretizedprojections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomDiscretizedProjections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnearpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhashes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpcabinaryprojections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCABinaryProjections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nearpy/hashes/randombinaryprojections.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnearpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhashes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlshash\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLSHash\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcsr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcsc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m from ._sparsetools import (csr_tocsc, csr_tobsr, csr_count_blocks,\n\u001b[0m\u001b[1;32m     14\u001b[0m                            get_csr_submatrix)\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msputils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mupcast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_index_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "from nearpy import Engine\n",
    "from nearpy.hashes import RandomBinaryProjections\n",
    "\n",
    "# Dimension of our vector space\n",
    "dimension = 500\n",
    "\n",
    "# Create a random binary hash with 10 bits\n",
    "rbp = RandomBinaryProjections('rbp', 10)\n",
    "\n",
    "# Create engine with pipeline configuration\n",
    "engine = Engine(dimension, lshashes=[rbp])\n",
    "\n",
    "# Index 1000000 random vectors (set their data to a unique string)\n",
    "for index in range(100000):\n",
    "    v = numpy.random.randn(dimension)\n",
    "    engine.store_vector(v, 'data_%d' % index)\n",
    "\n",
    "# Create random query vector\n",
    "query = numpy.random.randn(dimension)\n",
    "\n",
    "# Get nearest neighbours\n",
    "N = engine.neighbours(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nearpy\n",
    "from nearpy.filters import NearestFilter\n",
    "import sklearn.preprocessing\n",
    "\n",
    "class NearPy(KNNIndex):\n",
    "    #VALID_METRICS = neighbors.NearPy.valid_metrics\n",
    "    #METHOD_PARAMS = neighbors.NearPy.params\n",
    "    \n",
    "    def build(self, data):        \n",
    "        #parameters init\n",
    "        if self.method_param == None:\n",
    "            self.method_param = {}\n",
    "            self.method_param['n_bits'] = 0.0 \n",
    "            self.method_param['hash_counts'] = 0.0\n",
    "            #self.method_param['filter'] = NearestFilter(10)\n",
    "        self._filter = NearestFilter(10)\n",
    "        self._metric = metric\n",
    "        \n",
    "        \n",
    "        hashes = []\n",
    "\n",
    "        for k in range(self._hash_counts):\n",
    "            nearpy_rbp = nearpy.hashes.RandomBinaryProjections(\n",
    "                'rbp_%d' % k, self._n_bits)\n",
    "            hashes.append(nearpy_rbp)\n",
    "\n",
    "        if self._metric == 'euclidean':\n",
    "            dist = nearpy.distances.EuclideanDistance()\n",
    "            self._nearpy_engine = nearpy.Engine(\n",
    "                data.shape[1],\n",
    "                lshashes=hashes,\n",
    "                distance=dist)\n",
    "        else:  # Default (angular) = Cosine distance\n",
    "            self._nearpy_engine = nearpy.Engine(\n",
    "                data.shape[1],\n",
    "                lshashes=hashes,\n",
    "                vector_filters=[self._filter])\n",
    "\n",
    "        if self._metric == 'angular':\n",
    "            data = sklearn.preprocessing.normalize(X, axis=1, norm='l2')\n",
    "        for i, x in enumerate(data):\n",
    "            self._nearpy_engine.store_vector(x, i)\n",
    "\n",
    "\n",
    "    def query_train(self, data, k):\n",
    "        self._filter.N = k\n",
    "        if self._metric == 'angular':\n",
    "            v = sklearn.preprocessing.normalize([v], axis=1, norm='l2')[0]\n",
    "        return [y for x, y, z in self._nearpy_engine.neighbours(v)]\n",
    "\n",
    "\n",
    "    def query(self, query, k):\n",
    "        self._filter.N = k\n",
    "        if self._metric == 'angular':\n",
    "            v = sklearn.preprocessing.normalize([v], axis=1, norm='l2')[0]\n",
    "        return [y for x, y, z in self._nearpy_engine.neighbours(v)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONNG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ngtpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4d388665de57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mngtpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mONNG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKNNIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ngtpy'"
     ]
    }
   ],
   "source": [
    "#from __future__ import absolute_import\n",
    "import ngtpy\n",
    "import numpy as np\n",
    "\n",
    "class ONNG(KNNIndex):\n",
    "    #VALID_METRICS = neighbors.ONNG.valid_metrics\n",
    "    \n",
    "    def build(self, data):\n",
    "        #metrics = {'euclidean': '2', 'angular': 'C'}\n",
    "        self._metric = metrics[metric]\n",
    "        self._object_type\n",
    "        self._edge_size_for_search = -2\n",
    "        self._build_time_limit = 4\n",
    "        self._epsilon = epsilon\n",
    "        if self.method_param == None:\n",
    "            self.method_param['edge'] == 0.0\n",
    "            self.method_param['outdegree'] == 0.0\n",
    "            self.method_param['indegree'] == 0.0\n",
    "\n",
    "        dim = len(data[0])\n",
    "        index_dir = 'indexes'\n",
    "        if not os.path.exists(index_dir):\n",
    "            os.makedirs(index_dir)\n",
    "        index = os.path.join(\n",
    "            index_dir,\n",
    "            'ONNG-{}-{}-{}'.format(self._edge_size, self._outdegree,\n",
    "                                   self._indegree))\n",
    "        anngIndex = os.path.join(index_dir, 'ANNG-' + str(self._edge_size))\n",
    "        if (not os.path.exists(index)) and (not os.path.exists(anngIndex)):\n",
    "            t = time.time()\n",
    "            args = ['ngt', 'create', '-it', '-p8', '-b500', '-ga', '-of',\n",
    "                    '-D' + self._metric, '-d' + str(dim),\n",
    "                    '-E' + str(self._edge_size), '-S0',\n",
    "                    '-e' + str(self._epsilon), '-P0', '-B30',\n",
    "                    '-T' + str(self._build_time_limit), anngIndex]\n",
    "            subprocess.call(args)\n",
    "            idx = ngtpy.Index(path=anngIndex)\n",
    "            idx.batch_insert(X, num_threads=24, debug=False)\n",
    "            idx.save()\n",
    "            idx.close()\n",
    "        if not os.path.exists(index):\n",
    "            t = time.time()\n",
    "            args = ['ngt', 'reconstruct-graph', '-mS',\n",
    "                    '-o ' + str(self._outdegree),\n",
    "                    '-i ' + str(self._indegree), anngIndex, index]\n",
    "            subprocess.call(args)\n",
    "        if os.path.exists(index):\n",
    "            t = time.time()\n",
    "            self.index = ngtpy.Index(index, read_only=True)\n",
    "            self.indexName = index\n",
    "        else:\n",
    "            print('ONNG: Problem.')\n",
    "        \n",
    "            \n",
    "    def query_train(self, data, k):    \n",
    "        neighbors, distances = self.index.search(\n",
    "            v, k, self._epsilon, self._edge_size_for_search,\n",
    "            with_distance=False)\n",
    "        return neighbors, distances\n",
    "        \n",
    "        \n",
    "    def query(self, query, k):\n",
    "        #check in what format results are, get neighbors, distances\n",
    "        neighbors, distances = self.index.search(\n",
    "            v, k, self._epsilon, self._edge_size_for_search,\n",
    "            with_distance=False)\n",
    "        return neighbors, distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FLANN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FLANN(KNNIndex):\n",
    "    #VALID_METRICS = neighbors.Flann.valid_metrics\n",
    "    \n",
    "    def build(self, data):\n",
    "        #parameters init\n",
    "        if self.method_param == None:\n",
    "            self.method_param = {}\n",
    "            self.method_param['target_precision'] = 0.9  # want 90% target precision  \n",
    "        self._metric = metric\n",
    "        \n",
    "        self.index = pyflann.FLANN(\n",
    "            target_precision=self._target_precision,\n",
    "            algorithm='autotuned', \n",
    "            log_level='info')\n",
    "        if self._metric == 'angular':\n",
    "            data = sklearn.preprocessing.normalize(data, axis=1, norm='l2')\n",
    "        self.index.build_index(data)\n",
    "\n",
    "\n",
    "###### \n",
    "    def query_train(self, data, k):\n",
    "        if self._metric == 'angular':\n",
    "            v = sklearn.preprocessing.normalize([v], axis=1, norm='l2')[0]\n",
    "        if v.dtype != numpy.float32:\n",
    "            v = v.astype(numpy.float32)\n",
    "        return self._flann.nn_index(v, n)[0][0]\n",
    "\n",
    "    def query(self, query, k):\n",
    "        if self._metric == 'angular':\n",
    "            v = sklearn.preprocessing.normalize([v], axis=1, norm='l2')[0]\n",
    "        if v.dtype != numpy.float32:\n",
    "            v = v.astype(numpy.float32)\n",
    "        return self._flann.nn_index(v, n)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RPForest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpforest\n",
    "import numpy\n",
    "\n",
    "\n",
    "class RPForest(KNNIndex):\n",
    "    #VALID_METRICS = neighbors.Annoy.valid_metrics\n",
    "    \n",
    "    def build(self, data):\n",
    "        n_trees = 5 + int(round((data.shape[0]) ** 0.5 / 20))\n",
    "        #n_iters = max(5, int(round(np.log2(data.shape[0]))))\n",
    "        leaf_size = ?\n",
    "        \n",
    "        self.index = rpforest.RPForest(leaf_size=leaf_size, no_trees=n_trees)\n",
    "        \n",
    "        #if data.dtype != numpy.double:\n",
    "        #    data = numpy.array(data).astype(numpy.double)\n",
    "        self.index.fit(data)\n",
    "\n",
    "    def query_train(self, data, k):\n",
    "        neighbors, distances = self._model.query(data[0], k)\n",
    "        return neighbors, distances\n",
    "\n",
    "    def query(self, query, k):\n",
    "        neighbors, distances = self._model.query(data[0], k)\n",
    "        return neighbors, distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hnswlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1e+03 ns, total: 5 µs\n",
      "Wall time: 8.82 µs\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hnswlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-598d8182eb8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mhnswlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hnswlib'"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "import hnswlib\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class HnswLib(KNNIndex):\n",
    "    #VALID_METRICS = neighbors.Annoy.valid_metrics\n",
    "    \n",
    "    def build(self,data):  \n",
    "        #parameter init\n",
    "        #self.metric = {'angular': 'cosine', 'euclidean': 'l2'}[metric]\n",
    "        if self.method_param == None:\n",
    "            self.method_param = {}\n",
    "            self.method_param[\"efConstruction\"] = 200\n",
    "            self.method_param[\"M\"] = 16\n",
    "            self.method_param[\"efRecall\"] = 10\n",
    "            #self.name = 'hnswlib (%s)' % (self.method_param)\n",
    "        \n",
    "        \n",
    "        self.index = hnswlib.Index(space=self.metric, dim=len(data[0]))\n",
    "        self.index.init_index(max_elements=len(data),\n",
    "                          ef_construction=self.method_param[\"efConstruction\"],\n",
    "                          M=self.method_param[\"M\"])\n",
    "        data_labels = np.arange(len(data))\n",
    "        self.index.add_items(np.asarray(data), data_labels)\n",
    "        self.index.set_num_threads(self.n_jobs)\n",
    "        self.index.set_ef(self.method_param[\"efRecall\"])\n",
    "\n",
    "    def query(self, query, k):\n",
    "        neighbors, distances = self.index.knn_query(query, k=k)\n",
    "        return neighbors, distances\n",
    "    \n",
    "    def query_train(self, data, k):\n",
    "        neighbors, distances = self.index.knn_query(data, k=k)\n",
    "        return neighbors, distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annoy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 2 µs, total: 6 µs\n",
      "Wall time: 13.1 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "from openTSNE.nearest_neighbors import KNNIndex\n",
    "\n",
    "# Annoy:\n",
    "\n",
    "import annoy\n",
    "import numpy as np\n",
    "\n",
    "class Annoy(KNNIndex):\n",
    "    #VALID_METRICS = neighbors.Annoy.valid_metrics\n",
    "    \n",
    "    def build(self, data):\n",
    "        num_items, vector_length = data.shape\n",
    "        self.index = annoy.AnnoyIndex(vector_length, metric=self.metric)\n",
    "        #for i, x in enumerate(data):\n",
    "        #    self.index.add_item(i, x.tolist())\n",
    "        \n",
    "        n_trees = 5 + int(round((data.shape[0]) ** 0.5 / 20))\n",
    "        \n",
    "        for idx in range(num_items):\n",
    "            self.index.add_item(idx, data[idx])\n",
    "        self.index.build(n_trees)\n",
    "    \n",
    "        \n",
    "    def query_train(self, data, k):\n",
    "        #add search_k parameter: tradeoff between speed and accuracy?\n",
    "        #neighbors[i], distances[i] = self.index.get_nns_by_item(i, n=k, search_k=-1 ,include_distances=True)\n",
    "        #neighbors[i], distances[i] = self.index.get_nns_by_vector(data[i], n=k, search_k=-1, include_distances=True)\n",
    "        neighbors = np.empty((data.shape[0],k))\n",
    "        distances = np.empty((data.shape[0],k))\n",
    "        #print(k)\n",
    "        #print(data.shape)\n",
    "        #print(neighbors)\n",
    "        for i in range(len(data)):\n",
    "            neighbors_single, distances_single = np.asarray(self.index.get_nns_by_vector(data[i], n=k, search_k=-1, include_distances=True))\n",
    "            #print(neighbors_single)\n",
    "            #print(neighbors[i])\n",
    "            neighbors[i] = neighbors_single\n",
    "            distances[i] = distances_single\n",
    "            #neighbors[i], distances[i] = np.asarray(self.index.get_nns_by_item(i, n=k, search_k=-1 ,include_distances=True))\n",
    "        return neighbors, distances\n",
    "\n",
    "\n",
    "    def query(self, query, k):\n",
    "        #query ????\n",
    "        #neighbors, distances = self.index.get_nns_by_item(3, n=k, search_k=-1 ,include_distances=True)\n",
    "        neighbors = np.empty(data.shape[0])\n",
    "        distances = np.empty(data.shape[0])\n",
    "        for i in range(len(data)):\n",
    "            neighbors_single, distances_single = np.asarray(self.index.get_nns_by_vector(data[i], n=k, search_k=-1, include_distances=True))\n",
    "            neighbors[i] = neighbors_single\n",
    "            distances[i] = distances_single\n",
    "        return neighbors, distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbors:\n",
      "[[  0.  17.   4. ...  73.  63.  58.]\n",
      " [  1.  12.  45. ...  68.  65.  63.]\n",
      " [  2.  47.   3. ...  63.  65.  68.]\n",
      " ...\n",
      " [147. 110. 111. ... 122.  59.  64.]\n",
      " [148. 136. 115. ...  59.  53.  64.]\n",
      " [149. 127. 138. ...  79. 107. 109.]]\n",
      "Distances:\n",
      "[[0.         0.10000001 0.14142123 ... 3.65786791 3.69999957 3.74966645]\n",
      " [0.         0.14142129 0.14142129 ... 3.69188285 3.69999981 3.71214199]\n",
      " [0.         0.1414213  0.24494903 ... 3.87943292 3.88072157 3.89615202]\n",
      " ...\n",
      " [0.         0.2236068  0.34641021 ... 1.93132067 1.95703852 1.96723151]\n",
      " [0.         0.24494903 0.30000019 ... 2.13307285 2.15870333 2.2022717 ]\n",
      " [0.         0.28284246 0.31622747 ... 1.84390891 1.84661877 1.88148856]]\n",
      "P:\n",
      "  (0, 58)\t1.1123856191126478e-48\n",
      "  (0, 63)\t1.629381818051472e-47\n",
      "  (0, 73)\t1.5443295993298925e-46\n",
      "  (0, 65)\t7.618908252567122e-46\n",
      "  (0, 87)\t1.2659956581135655e-45\n",
      "  (0, 51)\t1.361279451433849e-45\n",
      "  (0, 75)\t3.7587606280968164e-45\n",
      "  (0, 91)\t4.041633163961909e-45\n",
      "  (0, 106)\t5.024286834345004e-45\n",
      "  (0, 78)\t1.1373116778461108e-43\n",
      "  (0, 85)\t2.0320429640373955e-43\n",
      "  (0, 66)\t1.4684333760073635e-41\n",
      "  (0, 74)\t3.770849500982889e-41\n",
      "  (0, 55)\t3.7708940636562237e-41\n",
      "  (0, 84)\t4.687778032095442e-41\n",
      "  (0, 97)\t1.2268324422718476e-39\n",
      "  (0, 90)\t6.052593783026402e-39\n",
      "  (0, 61)\t3.2721531985417874e-37\n",
      "  (0, 94)\t1.0645757646313081e-35\n",
      "  (0, 62)\t1.4229865461859848e-35\n",
      "  (0, 96)\t3.654254097655959e-35\n",
      "  (0, 53)\t1.55931299641511e-34\n",
      "  (0, 71)\t3.463470407810223e-34\n",
      "  (0, 95)\t3.724106684873443e-34\n",
      "  (0, 99)\t7.692885885901127e-34\n",
      "  :\t:\n",
      "  (149, 66)\t7.330878315897751e-05\n",
      "  (149, 116)\t7.599730076727377e-05\n",
      "  (149, 78)\t7.033520848381596e-05\n",
      "  (149, 56)\t0.00010558619198568894\n",
      "  (149, 91)\t8.089484542949024e-05\n",
      "  (149, 110)\t0.00010514943370423587\n",
      "  (149, 146)\t0.00012319205315800593\n",
      "  (149, 137)\t0.00012026321604423454\n",
      "  (149, 103)\t0.00013056033586095764\n",
      "  (149, 114)\t0.00021544346852801004\n",
      "  (149, 147)\t0.0001061385506654824\n",
      "  (149, 111)\t0.00012617327534216203\n",
      "  (149, 63)\t0.00011659041473327155\n",
      "  (149, 113)\t0.0002226519553219883\n",
      "  (149, 133)\t0.00019368156378631995\n",
      "  (149, 123)\t0.00018253938249201694\n",
      "  (149, 126)\t0.0002449212382791976\n",
      "  (149, 121)\t0.0003351397451320423\n",
      "  (149, 83)\t0.0003792148904964361\n",
      "  (149, 70)\t0.0004211395245416383\n",
      "  (149, 142)\t0.0004301334718734168\n",
      "  (149, 101)\t0.0004301334718734168\n",
      "  (149, 138)\t0.0004307341317329757\n",
      "  (149, 127)\t0.00046861379804921465\n",
      "  (149, 149)\t0.00069446280453884\n",
      "\n",
      "knn_index:\n",
      "<__main__.Annoy object at 0x11aecb7f0>\n"
     ]
    }
   ],
   "source": [
    "affinities_train = MultiANNPerplexityBasedNN(\n",
    "    x,\n",
    "    perplexity=30,\n",
    "    method=\"annoy\",\n",
    "    metric=\"euclidean\",\n",
    "    n_jobs=8,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "#possible solution\n",
    "#affinities_train.knn_index = stelmach.build_knn_index()\n",
    "\n",
    "print(\"P:\")\n",
    "print(affinities_train.P)\n",
    "print(\"\")\n",
    "\n",
    "#print(\"data:\")\n",
    "#print(affinities_train.data)\n",
    "#print(\"\")\n",
    "\n",
    "print(\"knn_index:\")\n",
    "print(affinities_train.knn_index)\n",
    "\n",
    "#print(\".index\")\n",
    "#print(affinities_train.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbors:\n",
      "[[ 17   4  28 ...  63  58  68]\n",
      " [ 12  45  34 ...  65  63  58]\n",
      " [ 47   3   6 ...  65  68  58]\n",
      " ...\n",
      " [110 111 145 ...  59  64 131]\n",
      " [136 115 110 ...  53  64  69]\n",
      " [127 138 142 ... 107 109 135]]\n",
      "Distances:\n",
      "[[0.10000001 0.14142122 0.14142122 ... 3.69999975 3.74966645 3.76828862]\n",
      " [0.14142129 0.1414213  0.14142131 ... 3.69999985 3.71214194 3.78813912]\n",
      " [0.14142131 0.24494903 0.26457514 ... 3.88072164 3.89615202 3.97492132]\n",
      " ...\n",
      " [0.2236068  0.34641021 0.36055499 ... 1.95703851 1.96723154 2.00997534]\n",
      " [0.24494903 0.30000019 0.55677664 ... 2.15870338 2.2022717  2.20454074]\n",
      " [0.28284245 0.31622746 0.33166242 ... 1.84661878 1.88148856 2.11896179]]\n",
      "P:\n",
      "  (0, 68)\t1.6192509157967902e-47\n",
      "  (0, 58)\t4.313007103779627e-47\n",
      "  (0, 63)\t5.7441069565559964e-46\n",
      "  (0, 73)\t5.0271385917781364e-45\n",
      "  (0, 65)\t2.3437119481052305e-44\n",
      "  (0, 87)\t3.82501882591911e-44\n",
      "  (0, 51)\t4.1022817234324965e-44\n",
      "  (0, 75)\t1.0926730616423587e-43\n",
      "  (0, 91)\t1.1718826756182114e-43\n",
      "  (0, 106)\t1.445613427848103e-43\n",
      "  (0, 78)\t2.929782156535499e-42\n",
      "  (0, 85)\t5.128108375014417e-42\n",
      "  (0, 66)\t3.1840942962733162e-40\n",
      "  (0, 74)\t7.907790351990183e-40\n",
      "  (0, 55)\t7.907879405736152e-40\n",
      "  (0, 84)\t9.755070945001695e-40\n",
      "  (0, 97)\t2.274007875115149e-38\n",
      "  (0, 90)\t1.0601779850804045e-37\n",
      "  (0, 61)\t4.9756667113335234e-36\n",
      "  (0, 94)\t1.4308266236644748e-34\n",
      "  (0, 62)\t1.8929717249386524e-34\n",
      "  (0, 96)\t4.7013500774550156e-34\n",
      "  (0, 53)\t1.905568265125329e-33\n",
      "  (0, 71)\t4.1145091594545706e-33\n",
      "  (0, 95)\t4.412770972959368e-33\n",
      "  :\t:\n",
      "  (149, 66)\t7.987276353552929e-05\n",
      "  (149, 72)\t7.776102190962562e-05\n",
      "  (149, 116)\t8.294502782435491e-05\n",
      "  (149, 78)\t7.63984373727279e-05\n",
      "  (149, 56)\t0.00011604088371159978\n",
      "  (149, 91)\t8.847211447038081e-05\n",
      "  (149, 110)\t0.0001155930921077133\n",
      "  (149, 146)\t0.00013682933064326975\n",
      "  (149, 103)\t0.00014434100098356572\n",
      "  (149, 137)\t0.00013270328915247594\n",
      "  (149, 114)\t0.00025358551744169823\n",
      "  (149, 147)\t0.00011657581650008873\n",
      "  (149, 111)\t0.00013931531504102605\n",
      "  (149, 63)\t0.00012855165586083965\n",
      "  (149, 113)\t0.0002504473830516457\n",
      "  (149, 133)\t0.00021920093179417441\n",
      "  (149, 123)\t0.00020370847652707866\n",
      "  (149, 126)\t0.0002753409297052965\n",
      "  (149, 121)\t0.00038004579286253964\n",
      "  (149, 83)\t0.0004315819902365567\n",
      "  (149, 70)\t0.00048347894643794074\n",
      "  (149, 101)\t0.0004828529855161922\n",
      "  (149, 142)\t0.0004828529855161922\n",
      "  (149, 138)\t0.0004872942652771988\n",
      "  (149, 127)\t0.0005317474317429881\n",
      "\n",
      "data:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MultiANNPerplexityBasedNN' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-239-339961f0809c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maffinities_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MultiANNPerplexityBasedNN' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "affinities_train = MultiANNPerplexityBasedNN(\n",
    "    x,\n",
    "    perplexity=30,\n",
    "    method=\"approx\",\n",
    "    metric=\"euclidean\",\n",
    "    n_jobs=8,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "#possible solution\n",
    "#affinities_train.knn_index = stelmach.build_knn_index()\n",
    "\n",
    "print(\"P:\")\n",
    "print(affinities_train.P)\n",
    "print(\"\")\n",
    "\n",
    "#print(\"data:\")\n",
    "#print(affinities_train.data)\n",
    "#print(\"\")\n",
    "\n",
    "print(\"knn_index:\")\n",
    "print(affinities_train.knn_index)\n",
    "\n",
    "#print(\".index\")\n",
    "#print(affinities_train.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import affinity_multiann.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import operator\n",
    "from functools import reduce\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "#from . import nearest_neighbors\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "from openTSNE.affinity import PerplexityBasedNN, MultiscaleMixture, FixedSigmaNN, joint_probabilities_nn\n",
    "from openTSNE import nearest_neighbors\n",
    "\n",
    "class MultiANNPerplexityBasedNN(PerplexityBasedNN):\n",
    "    \"\"\"Compute affinities using nearest neighbors.\n",
    "    \"\"\"\n",
    "\n",
    "    #super init !    \n",
    "    def __init__(\n",
    "        self,\n",
    "        data,\n",
    "        perplexity=30,\n",
    "        method=\"approx\",\n",
    "        metric=\"euclidean\",\n",
    "        metric_params=None,\n",
    "        symmetrize=True,\n",
    "        n_jobs=1,\n",
    "        random_state=None,\n",
    "    ):\n",
    "        self.n_samples = data.shape[0]\n",
    "        self.perplexity = self.check_perplexity(perplexity)\n",
    "\n",
    "        self.knn_index = build_knn_index(\n",
    "            data, method, metric, metric_params, n_jobs, random_state\n",
    "        )\n",
    "\n",
    "        # Find and store the nearest neighbors so we can reuse them if the\n",
    "        # perplexity is ever lowered\n",
    "        k_neighbors = min(self.n_samples - 1, int(3 * self.perplexity))\n",
    "        self.__neighbors, self.__distances = self.knn_index.query_train(\n",
    "            data, k=k_neighbors\n",
    "        )\n",
    "        print(\"Neighbors:\")\n",
    "        print(self.__neighbors)\n",
    "        #print(len(self.__neighbors))\n",
    "        print(\"Distances:\")\n",
    "        print(self.__distances)\n",
    "        #print(len(self.__distances[0]))\n",
    "\n",
    "        self.P = joint_probabilities_nn(\n",
    "            self.__neighbors,\n",
    "            self.__distances,\n",
    "            [self.perplexity],\n",
    "            symmetrize=symmetrize,\n",
    "            n_jobs=n_jobs,\n",
    "        )\n",
    "\n",
    "        self.n_jobs = n_jobs\n",
    "        \n",
    "        \n",
    "        \n",
    "def build_knn_index(\n",
    "    data, method, metric, metric_params=None, n_jobs=1, random_state=None\n",
    "):\n",
    "    methods = {\n",
    "        \"exact_alt\": nearest_neighbors.VPTree,\n",
    "        \"exact\": nearest_neighbors.BallTree,\n",
    "        \"approx\": nearest_neighbors.NNDescent,\n",
    "        #cs: options for ann algorithms\n",
    "        \"balltree\": nearest_neighbors.BallTree,\n",
    "        \"nndescent\": nearest_neighbors.NNDescent,\n",
    "        #\"annoy\": multi_nearest_neighbors.Annoy,\n",
    "        \"annoy\": Annoy,\n",
    "        #\"\": nearest_neighbors.,\n",
    "        #\"\": nearest_neighbors.,\n",
    "    }\n",
    "    if isinstance(method, nearest_neighbors.KNNIndex):\n",
    "        knn_index = method\n",
    "\n",
    "    elif method not in methods:\n",
    "        raise ValueError(\n",
    "            \"Unrecognized nearest neighbor algorithm `%s`. \"\n",
    "            \"Please choose one of the supported methods or \"\n",
    "            \"provide a valid `KNNIndex` instance.\" % method\n",
    "        )\n",
    "    else:\n",
    "        knn_index = methods[method](\n",
    "            metric=metric,\n",
    "            metric_params=metric_params,\n",
    "            n_jobs=n_jobs,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "\n",
    "    knn_index.build(data)\n",
    "\n",
    "    return knn_index        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MultiANNFixedSigmaNN(FixedSigmaNN):\n",
    "#     \"\"\"Compute affinities using using nearest neighbors and a fixed bandwidth\n",
    "#     for the Gaussians in the ambient space.\n",
    "# \n",
    "#     Using a fixed Gaussian bandwidth can enable us to find smaller clusters of\n",
    "#     data points than we might be able to using the automatically determined\n",
    "#     bandwidths using perplexity. Note however that this requires mostly trial\n",
    "#     and error.\n",
    "#     \"\"\"\n",
    "# \n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         data,\n",
    "#         sigma,\n",
    "#         k=30,\n",
    "#         method=\"exact\",\n",
    "#         metric=\"euclidean\",\n",
    "#         metric_params=None,\n",
    "#         symmetrize=True,\n",
    "#         n_jobs=1,\n",
    "#         random_state=None,\n",
    "#     ):\n",
    "#         self.n_samples = n_samples = data.shape[0]\n",
    "# \n",
    "#         if k >= self.n_samples:\n",
    "#             raise ValueError(\n",
    "#                 \"`k` (%d) cannot be larger than N-1 (%d).\" % (k, self.n_samples)\n",
    "#             )\n",
    "# \n",
    "#         knn_index, neighbors, distances = build_knn_index(\n",
    "#             data, method, k, metric, metric_params, n_jobs, random_state\n",
    "#         )\n",
    "# \n",
    "#         self.knn_index = knn_index\n",
    "# \n",
    "#         # Compute asymmetric pairwise input similarities\n",
    "#         conditional_P = np.exp(-distances ** 2 / (2 * sigma ** 2))\n",
    "#         conditional_P /= np.sum(conditional_P, axis=1)[:, np.newaxis]\n",
    "# \n",
    "#         P = sp.csr_matrix(\n",
    "#             (conditional_P.ravel(), neighbors.ravel(), range(0, n_samples * k + 1, k)),\n",
    "#             shape=(n_samples, n_samples),\n",
    "#         )\n",
    "# \n",
    "#         # Symmetrize the probability matrix\n",
    "#         if symmetrize:\n",
    "#             P = (P + P.T) / 2\n",
    "# \n",
    "#         # Convert weights to probabilities\n",
    "#         P /= np.sum(P)\n",
    "# \n",
    "#         self.sigma = sigma\n",
    "#         self.k = k\n",
    "#         self.P = P\n",
    "#         self.n_jobs = n_jobs\n",
    "#\n",
    "#\n",
    "# class MultiANNMultiscaleMixture(MultiscaleMixture):\n",
    "#     \"\"\"Calculate affinities using a Gaussian mixture kernel.\n",
    "# \n",
    "#     Instead of using a single perplexity to compute the affinities between data\n",
    "#     points, we can use a multiscale Gaussian kernel instead. This allows us to\n",
    "#     incorporate long range interactions.\n",
    "#     \"\"\"\n",
    "# \n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         data,\n",
    "#         perplexities,\n",
    "#         method=\"exact\",\n",
    "#         metric=\"euclidean\",\n",
    "#         metric_params=None,\n",
    "#         symmetrize=True,\n",
    "#         n_jobs=1,\n",
    "#         random_state=None,\n",
    "#     ):\n",
    "#         self.n_samples = data.shape[0]\n",
    "# \n",
    "#         # We will compute the nearest neighbors to the max value of perplexity,\n",
    "#         # smaller values can just use indexing to truncate unneeded neighbors\n",
    "#         perplexities = self.check_perplexities(perplexities)\n",
    "#         max_perplexity = np.max(perplexities)\n",
    "#         k_neighbors = min(self.n_samples - 1, int(3 * max_perplexity))\n",
    "# \n",
    "#         self.knn_index, self.__neighbors, self.__distances = build_knn_index(\n",
    "#             data, method, k_neighbors, metric, metric_params, n_jobs, random_state\n",
    "#         )\n",
    "# \n",
    "#         self.P = self._calculate_P(\n",
    "#             self.__neighbors,\n",
    "#             self.__distances,\n",
    "#             perplexities,\n",
    "#             symmetrize=symmetrize,\n",
    "#             n_jobs=n_jobs,\n",
    "#         )\n",
    "# \n",
    "#         self.perplexities = perplexities\n",
    "#         self.n_jobs = n_jobs\n",
    "# \n",
    "# class MultiANNMultiscale(MultiANNMultiscaleMixture):\n",
    "#     \"\"\"Calculate affinities using averaged Gaussian perplexities.\n",
    "# \n",
    "#     In contrast to :class:`MultiscaleMixture`, which uses a Gaussian mixture\n",
    "#     kernel, here, we first compute single scale Gaussian kernels, convert them\n",
    "#     to probability distributions, then average them out between scales.\n",
    "# \n",
    "#     Please see the :ref:`parameter-guide` for more information.\n",
    "#     \"\"\"\n",
    "# \n",
    "#     @staticmethod\n",
    "#     def _calculate_P(\n",
    "#         neighbors,\n",
    "#         distances,\n",
    "#         perplexities,\n",
    "#         symmetrize=True,\n",
    "#         normalization=\"pair-wise\",\n",
    "#         n_reference_samples=None,\n",
    "#         n_jobs=1,\n",
    "#     ):\n",
    "#         # Compute normalized probabilities for each perplexity\n",
    "#         partial_Ps = [\n",
    "#             joint_probabilities_nn(\n",
    "#                 neighbors,\n",
    "#                 distances,\n",
    "#                 [perplexity],\n",
    "#                 symmetrize=symmetrize,\n",
    "#                 normalization=normalization,\n",
    "#                 n_reference_samples=n_reference_samples,\n",
    "#                 n_jobs=n_jobs,\n",
    "#             )\n",
    "#             for perplexity in perplexities\n",
    "#         ]\n",
    "#         # Sum them together, then normalize\n",
    "#         P = reduce(operator.add, partial_Ps, 0)\n",
    "# \n",
    "#         # Take care to properly normalize the affinity matrix\n",
    "#         if normalization == \"pair-wise\":\n",
    "#             P /= np.sum(P)\n",
    "#         elif normalization == \"point-wise\":\n",
    "#             P = sp.diags(np.asarray(1 / P.sum(axis=1)).ravel()) @ P\n",
    "# \n",
    "#         return P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Generate initial coordinates for our embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.77 ms, sys: 2.99 ms, total: 4.76 ms\n",
      "Wall time: 17.1 ms\n"
     ]
    }
   ],
   "source": [
    "%time init_train = initialization.pca(x, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Construct the `TSNEEmbedding` object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbors:\n",
      "[[  0.  17.   4. ...  73.  63.  58.]\n",
      " [  1.  12.  45. ...  68.  65.  63.]\n",
      " [  2.  47.   3. ...  63.  65.  68.]\n",
      " ...\n",
      " [147. 110. 111. ... 122.  59.  64.]\n",
      " [148. 136. 115. ...  59.  53.  64.]\n",
      " [149. 127. 138. ...  79. 107. 109.]]\n",
      "Distances:\n",
      "[[0.         0.10000001 0.14142123 ... 3.65786791 3.69999957 3.74966645]\n",
      " [0.         0.14142129 0.14142129 ... 3.69188285 3.69999981 3.71214199]\n",
      " [0.         0.1414213  0.24494903 ... 3.87943292 3.88072157 3.89615202]\n",
      " ...\n",
      " [0.         0.2236068  0.34641021 ... 1.93132067 1.95703852 1.96723151]\n",
      " [0.         0.24494903 0.30000019 ... 2.13307285 2.15870333 2.2022717 ]\n",
      " [0.         0.28284246 0.31622747 ... 1.84390891 1.84661877 1.88148856]]\n"
     ]
    }
   ],
   "source": [
    "affinities_train = MultiANNPerplexityBasedNN(\n",
    "    x,\n",
    "    perplexity=30,\n",
    "    method=\"annoy\",\n",
    "    metric=\"euclidean\",\n",
    "    n_jobs=8,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "embedding_train = TSNEEmbedding(\n",
    "    init_train,\n",
    "    affinities_train,\n",
    "    negative_gradient_method=\"fft\",\n",
    "    n_jobs=8,\n",
    "    callbacks=ErrorLogger(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BaseANN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-d82533cbd118>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mAnnoy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseANN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_trees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_search_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BaseANN' is not defined"
     ]
    }
   ],
   "source": [
    "class Annoy(BaseANN):\n",
    "    def __init__(self, metric, n_trees):\n",
    "        self._n_trees = n_trees\n",
    "        self._search_k = None\n",
    "        self._metric = metric\n",
    "\n",
    "    def fit(self, X):\n",
    "        self._annoy = annoy.AnnoyIndex(X.shape[1], metric=self._metric)\n",
    "        for i, x in enumerate(X):\n",
    "            self._annoy.add_item(i, x.tolist())\n",
    "        self._annoy.build(self._n_trees)\n",
    "\n",
    "    def set_query_arguments(self, search_k):\n",
    "        self._search_k = search_k\n",
    "\n",
    "    def query(self, v, n):\n",
    "        return self._annoy.get_nns_by_vector(v.tolist(), n, self._search_k)\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'Annoy(n_trees=%d, search_k=%d)' % (self._n_trees,\n",
    "                                                   self._search_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Optimize embedding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Early exaggeration phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embedding_train' is not defined"
     ]
    }
   ],
   "source": [
    "%time embedding_train_1 = embedding_train.optimize(n_iter=250, exaggeration=12, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'utils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-f5992a0a450d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_train_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'utils' is not defined"
     ]
    }
   ],
   "source": [
    "utils.plot(embedding_train_1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding_train_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embedding_train_1' is not defined"
     ]
    }
   ],
   "source": [
    "%time embedding_train_2 = embedding_train_1.optimize(n_iter=750, momentum=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'utils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-ec82416b96ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_train_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMACOSKO_COLORS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'utils' is not defined"
     ]
    }
   ],
   "source": [
    "utils.plot(embedding_train_2, y_train, colors=utils.MACOSKO_COLORS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding_train_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embedding_train_2' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embedding_test = embedding_train_2.prepare_partial(\n",
    "    x_test,\n",
    "    initialization=\"median\",\n",
    "    k=25,\n",
    "    perplexity=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'utils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-68ba9059eadd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMACOSKO_COLORS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'utils' is not defined"
     ]
    }
   ],
   "source": [
    "utils.plot(embedding_test, y_test, colors=utils.MACOSKO_COLORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embedding_test' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embedding_test_1 = embedding_test.optimize(\n",
    "    n_iter=100,\n",
    "    learning_rate=1,\n",
    "    exaggeration=2,\n",
    "    momentum=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'utils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-a4ac5fda05ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_test_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMACOSKO_COLORS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'utils' is not defined"
     ]
    }
   ],
   "source": [
    "utils.plot(embedding_test_1, y_test, colors=utils.MACOSKO_COLORS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Together\n",
    "\n",
    "We superimpose the transformed points onto the original embedding with larger opacity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-45d4316b14b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_train_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMACOSKO_COLORS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_test_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMACOSKO_COLORS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "utils.plot(embedding_train_2, y_train, colors=utils.MACOSKO_COLORS, alpha=0.25, ax=ax)\n",
    "utils.plot(embedding_test_1, y_test, colo rs=utils.MACOSKO_COLORS, alpha=0.75, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test inheritance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Previous\n",
      "Init Base\n",
      "Init Super\n"
     ]
    }
   ],
   "source": [
    "class base():\n",
    "    def __init__(self):\n",
    "        init = \"Init Base\"\n",
    "        print(init)\n",
    "    def bark(self):\n",
    "        print(\"woof\")\n",
    "        \n",
    "#currently (full override):\n",
    "class over(base):\n",
    "    def __init__(self):\n",
    "        init = \"Init Previous\"\n",
    "        print(init)\n",
    "    def berk(self):\n",
    "        print(\"dog.bark(self)\")\n",
    "\n",
    "billo = dug()  \n",
    "\n",
    "#with super:\n",
    "class sup(base):\n",
    "    def __init__(self):\n",
    "        super(deg, self).__init__()\n",
    "        init = \"Init Super\"\n",
    "        print(init)\n",
    "    def berk(self):\n",
    "        print(\"dog.bark(self)\")\n",
    "\n",
    "bello = deg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: (150, 4)\n",
      "arr + entry [0. 1. 2. 3.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"x.shape: {}\".format(x.shape))\n",
    "arr = np.empty(x.shape)\n",
    "#print(\"arr: {}\".format(arr))\n",
    "entry = [0,1,2,3]\n",
    "arr[0] = entry\n",
    "print(\"arr + entry {}\".format(arr[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 2. 3.]\n",
      " [1. 1. 2. 3.]\n",
      " [2. 1. 2. 3.]\n",
      " [3. 1. 2. 3.]\n",
      " [4. 1. 2. 3.]]\n",
      "[[ 0. 20. 30. 40.]\n",
      " [10. 20. 30. 40.]\n",
      " [20. 20. 30. 40.]\n",
      " [30. 20. 30. 40.]\n",
      " [40. 20. 30. 40.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#index = neighbors, distances\n",
    "data = [[[0,1,2,3],[0,20,30,40]],[[1,1,2,3],[10,20,30,40]],[[2,1,2,3],[20,20,30,40]],\n",
    "[[3,1,2,3],[30,20,30,40]],[[4,1,2,3],[40,20,30,40]]]\n",
    "\n",
    "neighbors = np.empty((5,4))\n",
    "distances = np.empty((5,4))\n",
    "\n",
    "for i in range(len(data)):\n",
    "    #neighbors_single, distances_single = np.asarray(data[i])\n",
    "    neighbors[i], distances[i] = np.asarray(data[i])\n",
    "#    neighbors[i] = neighbors_single\n",
    "#    distances[i] = distances_single\n",
    "      \n",
    "print(neighbors)\n",
    "print(distances)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#indexarr = np.asarray(indexlist)\n",
    "#np.append(indexarr[1],np.asarray(indexlist1)[1], axis=0)\n",
    "#neig, dist = indexarr[1]\n",
    "#np.append(indexarr[0],np.asarray(indexlist1)[1], axis=0)\n",
    "\n",
    "#print(indexarr)\n",
    "\n",
    "\n",
    "#neigh = np.empty((4,4))\n",
    "#dist = np.empty\n",
    "\n",
    "#empty[0] = indexarr[0]\n",
    "#print(\"\")\n",
    "#print(empty)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
