{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### python test class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config files\n",
    "\n",
    "Provide option to input config files, in the form I want to get, if they don't provide any, you give/use default values. \n",
    ".txt format\n",
    "\n",
    "Describe it in the documentation how it should look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openTSNE import TSNEEmbedding\n",
    "from openTSNE import initialization\n",
    "from openTSNE.callbacks import ErrorLogger\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "x, y = iris[\"data\"], iris[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set contains 150 samples with 4 features\n"
     ]
    }
   ],
   "source": [
    "print(\"Data set contains %d samples with %d features\" % x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 training samples\n",
      "50 test samples\n"
     ]
    }
   ],
   "source": [
    "print(\"%d training samples\" % x_train.shape[0])\n",
    "print(\"%d test samples\" % x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a t-SNE embedding\n",
    "\n",
    "Like in the *simple_usage* notebook, we will run the standard t-SNE optimization.\n",
    "\n",
    "This example shows the standard t-SNE optimization. Much can be done in order to better preserve global structure and improve embedding quality. Please refer to the *preserving_global_structure* notebook for some examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Compute the affinities between data points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNIndex_Elements:\n",
    "    def __init__(self, metric, metric_params=None, n_jobs=1, random_state=None):\n",
    "        self.index = None\n",
    "        self.metric = metric\n",
    "        self.metric_params = metric_params\n",
    "        self.n_jobs = n_jobs\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def build(self, data):\n",
    "        \"\"\"Build the index so we can query nearest neighbors.\"\"\"\n",
    "\n",
    "    def query_train(self, data, k):\n",
    "        \"\"\"Query the index for the points used to build index.\"\"\"\n",
    "\n",
    "    def query(self, query, k):\n",
    "        \"\"\"Query the index with new points.\"\"\"\n",
    "\n",
    "    def check_metric(self, metric):\n",
    "        \"\"\"Check that the metric is supported by the KNNIndex instance.\"\"\"\n",
    "\n",
    "class Annoy:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "#####       \n",
    "#self.knn_index = build_knn_index(\n",
    "#            data, method, metric, metric_params, n_jobs, random_state\n",
    "#        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import affinity_multiann.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import operator\n",
    "from functools import reduce\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "#from . import nearest_neighbors\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "from openTSNE.affinity import PerplexityBasedNN, MultiscaleMixture, FixedSigmaNN, joint_probabilities_nn\n",
    "from openTSNE import nearest_neighbors\n",
    "\n",
    "class MultiANNPerplexityBasedNN(PerplexityBasedNN):\n",
    "    \"\"\"Compute affinities using nearest neighbors.\n",
    "    \"\"\"\n",
    "\n",
    "    #super init !    \n",
    "    def __init__(\n",
    "        self,\n",
    "        data,\n",
    "        perplexity=30,\n",
    "        method=\"approx\",\n",
    "        metric=\"euclidean\",\n",
    "        metric_params=None,\n",
    "        symmetrize=True,\n",
    "        n_jobs=1,\n",
    "        random_state=None,\n",
    "    ):\n",
    "        self.n_samples = data.shape[0]\n",
    "        self.perplexity = self.check_perplexity(perplexity)\n",
    "\n",
    "        self.knn_index = build_knn_index(\n",
    "            data, method, metric, metric_params, n_jobs, random_state\n",
    "        )\n",
    "\n",
    "        # Find and store the nearest neighbors so we can reuse them if the\n",
    "        # perplexity is ever lowered\n",
    "        k_neighbors = min(self.n_samples - 1, int(3 * self.perplexity))\n",
    "        self.__neighbors, self.__distances = self.knn_index.query_train(\n",
    "            data, k=k_neighbors\n",
    "        )\n",
    "        #print(\"Neighbors:\")\n",
    "        #print(self.__neighbors)\n",
    "        #print(len(self.__neighbors))\n",
    "        #print(\"Distances:\")\n",
    "        #print(self.__distances)\n",
    "        #print(len(self.__distances[0]))\n",
    "\n",
    "        self.P = joint_probabilities_nn(\n",
    "            self.__neighbors,\n",
    "            self.__distances,\n",
    "            [self.perplexity],\n",
    "            symmetrize=symmetrize,\n",
    "            n_jobs=n_jobs,\n",
    "        )\n",
    "\n",
    "        self.n_jobs = n_jobs\n",
    "        \n",
    "        \n",
    "        \n",
    "def build_knn_index(\n",
    "    data, method, metric, metric_params=None, n_jobs=1, random_state=None\n",
    "):\n",
    "    methods = {\n",
    "        #\"exact_alt\": nearest_neighbors.VPTree,\n",
    "        \"exact\": nearest_neighbors.BallTree,\n",
    "        \"approx\": nearest_neighbors.NNDescent,\n",
    "        #cs: options for ann algorithms\n",
    "        \"balltree\": nearest_neighbors.BallTree,\n",
    "        \"nndescent\": nearest_neighbors.NNDescent,\n",
    "        #\"annoy\": multi_nearest_neighbors.Annoy, (if filelocation in sumfile)\n",
    "        #\"annoy\": algorithms.annoy.Annoy (if filelocation in folder)\n",
    "        \"annoy\": Annoy,\n",
    "        #\"hnswlib\": Hnswlib,\n",
    "        #\"rpforest\": RPForest,\n",
    "        #\"flann\": FLANN,\n",
    "        #\"onng\": ONNG,\n",
    "        \"nearpy\": NearPy,\n",
    "    }\n",
    "    if isinstance(method, nearest_neighbors.KNNIndex):\n",
    "        knn_index = method\n",
    "\n",
    "    elif method not in methods:\n",
    "        raise ValueError(\n",
    "            \"Unrecognized nearest neighbor algorithm `%s`. \"\n",
    "            \"Please choose one of the supported methods or \"\n",
    "            \"provide a valid `KNNIndex` instance.\" % method\n",
    "        )\n",
    "    else:\n",
    "        knn_index = methods[method](\n",
    "            metric=metric,\n",
    "            metric_params=metric_params,\n",
    "            n_jobs=n_jobs,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "\n",
    "    knn_index.build(data)\n",
    "\n",
    "    return knn_index        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MultiANNFixedSigmaNN(FixedSigmaNN):\n",
    "#     \"\"\"Compute affinities using using nearest neighbors and a fixed bandwidth\n",
    "#     for the Gaussians in the ambient space.\n",
    "# \n",
    "#     Using a fixed Gaussian bandwidth can enable us to find smaller clusters of\n",
    "#     data points than we might be able to using the automatically determined\n",
    "#     bandwidths using perplexity. Note however that this requires mostly trial\n",
    "#     and error.\n",
    "#     \"\"\"\n",
    "# \n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         data,\n",
    "#         sigma,\n",
    "#         k=30,\n",
    "#         method=\"exact\",\n",
    "#         metric=\"euclidean\",\n",
    "#         metric_params=None,\n",
    "#         symmetrize=True,\n",
    "#         n_jobs=1,\n",
    "#         random_state=None,\n",
    "#     ):\n",
    "#         self.n_samples = n_samples = data.shape[0]\n",
    "# \n",
    "#         if k >= self.n_samples:\n",
    "#             raise ValueError(\n",
    "#                 \"`k` (%d) cannot be larger than N-1 (%d).\" % (k, self.n_samples)\n",
    "#             )\n",
    "# \n",
    "#         knn_index, neighbors, distances = build_knn_index(\n",
    "#             data, method, k, metric, metric_params, n_jobs, random_state\n",
    "#         )\n",
    "# \n",
    "#         self.knn_index = knn_index\n",
    "# \n",
    "#         # Compute asymmetric pairwise input similarities\n",
    "#         conditional_P = np.exp(-distances ** 2 / (2 * sigma ** 2))\n",
    "#         conditional_P /= np.sum(conditional_P, axis=1)[:, np.newaxis]\n",
    "# \n",
    "#         P = sp.csr_matrix(\n",
    "#             (conditional_P.ravel(), neighbors.ravel(), range(0, n_samples * k + 1, k)),\n",
    "#             shape=(n_samples, n_samples),\n",
    "#         )\n",
    "# \n",
    "#         # Symmetrize the probability matrix\n",
    "#         if symmetrize:\n",
    "#             P = (P + P.T) / 2\n",
    "# \n",
    "#         # Convert weights to probabilities\n",
    "#         P /= np.sum(P)\n",
    "# \n",
    "#         self.sigma = sigma\n",
    "#         self.k = k\n",
    "#         self.P = P\n",
    "#         self.n_jobs = n_jobs\n",
    "#\n",
    "#\n",
    "# class MultiANNMultiscaleMixture(MultiscaleMixture):\n",
    "#     \"\"\"Calculate affinities using a Gaussian mixture kernel.\n",
    "# \n",
    "#     Instead of using a single perplexity to compute the affinities between data\n",
    "#     points, we can use a multiscale Gaussian kernel instead. This allows us to\n",
    "#     incorporate long range interactions.\n",
    "#     \"\"\"\n",
    "# \n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         data,\n",
    "#         perplexities,\n",
    "#         method=\"exact\",\n",
    "#         metric=\"euclidean\",\n",
    "#         metric_params=None,\n",
    "#         symmetrize=True,\n",
    "#         n_jobs=1,\n",
    "#         random_state=None,\n",
    "#     ):\n",
    "#         self.n_samples = data.shape[0]\n",
    "# \n",
    "#         # We will compute the nearest neighbors to the max value of perplexity,\n",
    "#         # smaller values can just use indexing to truncate unneeded neighbors\n",
    "#         perplexities = self.check_perplexities(perplexities)\n",
    "#         max_perplexity = np.max(perplexities)\n",
    "#         k_neighbors = min(self.n_samples - 1, int(3 * max_perplexity))\n",
    "# \n",
    "#         self.knn_index, self.__neighbors, self.__distances = build_knn_index(\n",
    "#             data, method, k_neighbors, metric, metric_params, n_jobs, random_state\n",
    "#         )\n",
    "# \n",
    "#         self.P = self._calculate_P(\n",
    "#             self.__neighbors,\n",
    "#             self.__distances,\n",
    "#             perplexities,\n",
    "#             symmetrize=symmetrize,\n",
    "#             n_jobs=n_jobs,\n",
    "#         )\n",
    "# \n",
    "#         self.perplexities = perplexities\n",
    "#         self.n_jobs = n_jobs\n",
    "# \n",
    "# class MultiANNMultiscale(MultiANNMultiscaleMixture):\n",
    "#     \"\"\"Calculate affinities using averaged Gaussian perplexities.\n",
    "# \n",
    "#     In contrast to :class:`MultiscaleMixture`, which uses a Gaussian mixture\n",
    "#     kernel, here, we first compute single scale Gaussian kernels, convert them\n",
    "#     to probability distributions, then average them out between scales.\n",
    "# \n",
    "#     Please see the :ref:`parameter-guide` for more information.\n",
    "#     \"\"\"\n",
    "# \n",
    "#     @staticmethod\n",
    "#     def _calculate_P(\n",
    "#         neighbors,\n",
    "#         distances,\n",
    "#         perplexities,\n",
    "#         symmetrize=True,\n",
    "#         normalization=\"pair-wise\",\n",
    "#         n_reference_samples=None,\n",
    "#         n_jobs=1,\n",
    "#     ):\n",
    "#         # Compute normalized probabilities for each perplexity\n",
    "#         partial_Ps = [\n",
    "#             joint_probabilities_nn(\n",
    "#                 neighbors,\n",
    "#                 distances,\n",
    "#                 [perplexity],\n",
    "#                 symmetrize=symmetrize,\n",
    "#                 normalization=normalization,\n",
    "#                 n_reference_samples=n_reference_samples,\n",
    "#                 n_jobs=n_jobs,\n",
    "#             )\n",
    "#             for perplexity in perplexities\n",
    "#         ]\n",
    "#         # Sum them together, then normalize\n",
    "#         P = reduce(operator.add, partial_Ps, 0)\n",
    "# \n",
    "#         # Take care to properly normalize the affinity matrix\n",
    "#         if normalization == \"pair-wise\":\n",
    "#             P /= np.sum(P)\n",
    "#         elif normalization == \"point-wise\":\n",
    "#             P = sp.diags(np.asarray(1 / P.sum(axis=1)).ravel()) @ P\n",
    "# \n",
    "#         return P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import multi_nearest_neighbors.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### annparameters.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_method_param(method, data=None):\n",
    "    \"\"\"\n",
    "    Get method parameters based on approximate nearest neighbor algorithm and data (shape, vector)\n",
    "    \n",
    "    Input: name of method as string, data as np.array ([num_items][vector_length])\n",
    "    Output: method_param as directory. Keys corresponding to the method-specific parameters\n",
    "    \"\"\"\n",
    "    config_file = \"\"\n",
    "    config_file = None\n",
    "\n",
    "    if method == \"nearpy\":\n",
    "        if not config_file:\n",
    "            mp = {}\n",
    "            \n",
    "            # number of bits, as int\n",
    "            mp['n_bits'] = 4 # ????? How many as standard? \n",
    "            \n",
    "            # hash counts, as int\n",
    "            mp['hash_counts'] = 5 # ????? How many as standard? \n",
    "    \n",
    "    elif method == \"annoy\":\n",
    "\n",
    "        if not config_file:\n",
    "            n_items, vector_length = data.shape\n",
    "            mp = {}\n",
    "            \n",
    "            # number of trees, as int\n",
    "            mp[\"ntrees\"] = 5 + int(round((n_items) ** 0.5 / 20))\n",
    "    \n",
    "    else:\n",
    "        print(\"Error: ANN for init_method_param not found\")\n",
    "        return \n",
    "        \n",
    "    return mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_bits': 4, 'hash_counts': 5}\n"
     ]
    }
   ],
   "source": [
    "print(init_method_param(\"nearpy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NearPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openTSNE.nearest_neighbors import KNNIndex\n",
    "import nearpy\n",
    "from nearpy.filters import NearestFilter\n",
    "import sklearn.preprocessing\n",
    "\n",
    "class NearPy(KNNIndex):\n",
    "    #VALID_METRICS = neighbors.NearPy.valid_metrics\n",
    "    #METHOD_PARAMS = neighbors.NearPy.params (text/config file)\n",
    "    \n",
    "    def build(self, data): \n",
    "        n_items, vector_length = data.shape\n",
    "        print(data.shape)\n",
    "        #parameters init\n",
    "        method_param = init_method_param(\"nearpy\")\n",
    "        self.filter = NearestFilter(10)\n",
    "        \n",
    "        hashes = []\n",
    "        for k in range(method_param[\"hash_counts\"]):\n",
    "            nearpy_rbp = nearpy.hashes.RandomBinaryProjections(\n",
    "                'rbp_%d' % k, method_param[\"n_bits\"])\n",
    "            hashes.append(nearpy_rbp)\n",
    "\n",
    "        if self.metric == 'euclidean':\n",
    "            dist = nearpy.distances.EuclideanDistance()\n",
    "            self.index = nearpy.Engine(\n",
    "                vector_length,\n",
    "                lshashes=hashes,\n",
    "                distance=dist,\n",
    "                vector_filters=[self.filter])\n",
    "        else:  # Default (angular) = Cosine distance\n",
    "            self.index = nearpy.Engine(\n",
    "                vector_length,\n",
    "                lshashes=hashes,\n",
    "                vector_filters=[self.filter])\n",
    "            \n",
    "        #if self.metric == 'angular':\n",
    "            #data = sklearn.preprocessing.normalize(data, axis=1, norm='l2')\n",
    "        for i, x in enumerate(data):\n",
    "            self.index.store_vector(x, i)\n",
    "            \n",
    "    def query_train(self, data, k):\n",
    "        self.filter.N = k\n",
    "        print(k)\n",
    "        #if self.metric == 'angular':\n",
    "            #data = sklearn.preprocessing.normalize([data], axis=1, norm='l2')[0]\n",
    "        \n",
    "        neighbors = np.empty((data.shape[0],k), dtype=int)\n",
    "        distances = np.empty((data.shape[0],k))\n",
    "        for i in range(len(data)):\n",
    "            #vector = data[i]\n",
    "            neighbors_single = self.index.neighbours(data[i])\n",
    "            #print(len(neighbors_single))\n",
    "            #print(np.asarray(neighbors_single))\n",
    "            dp_n = []\n",
    "            dp_d = []\n",
    "            for j in range(len(neighbors_single)):\n",
    "                dp_n.append(neighbors_single[j][1])\n",
    "                dp_d.append(neighbors_single[j][2])\n",
    "            neighbors[i] = np.asarray(dp_n)\n",
    "            distances[i] = np.asarray(dp_d)\n",
    "            \n",
    "        print(\"dp_n: {}\".format(dp_n))\n",
    "        print(\"neighbors.shape: {}\".format(neighbors.shape))\n",
    "        #print(\"neighbors[0]: {}\".format(neighbors[0]))\n",
    "        \n",
    "        print(\"dp_d: {}\".format(dp_d))\n",
    "        print(\"distances.shape: {}\".format(distances.shape))\n",
    "        #print(\"distances[0]: {}\".format(distances[0]))\n",
    "        return neighbors, distances\n",
    "        #print(neighbors[0],distances[0])\n",
    "        #return neighbors, distances\n",
    "    \n",
    "\n",
    "    def query(self, query, k):\n",
    "        self.filter.N = k\n",
    "        if self.metric == 'angular':\n",
    "            query = sklearn.preprocessing.normalize([query], axis=1, norm='l2')[0]\n",
    "        return [y for x, y, z in self.index.neighbours(query)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "90\n",
      "dp_n: [149, 124, 117, 137, 109, 127, 116, 143, 101, 142, 138, 121, 106, 103, 120, 70, 147, 131, 84, 83, 104, 110, 115, 148, 66, 112, 144, 136, 140, 128, 125, 139, 102, 126, 111, 132, 113, 133, 55, 123, 90, 100, 145, 63, 78, 59, 77, 114, 91, 94, 146, 56, 105, 129, 135, 141, 107, 134, 89, 72, 96, 73, 85, 130, 61, 108, 99, 53, 88, 119, 95, 51, 54, 52, 122, 86, 97, 76, 92, 69, 58, 80, 118, 68, 67, 60, 82, 75, 74, 57]\n",
      "neighbors.shape: (150, 90)\n",
      "dp_d: [0.0, 0.013326045075696085, 0.01693272501435845, 0.020972957890048834, 0.03189362734680065, 0.032932540211072434, 0.03327924474671744, 0.03477885641723165, 0.03502305079662377, 0.03502305079662377, 0.035123030106931595, 0.03542922450058204, 0.036329849298748135, 0.039520227395661904, 0.03993388714500637, 0.04070918369663919, 0.04181292975683996, 0.04290657997998921, 0.043128106462641105, 0.043169406454368925, 0.04364471236253631, 0.044437354533735325, 0.044904359314600524, 0.04755526778337658, 0.04809155233234756, 0.04810678341742924, 0.04908976609455608, 0.05018421952556218, 0.05075591052406499, 0.05159062892050629, 0.052246726589631066, 0.05289900696489398, 0.05483399586863565, 0.054861563136403654, 0.05542667363846744, 0.056140936358780105, 0.058342339788423556, 0.059671875707460395, 0.06198674009314978, 0.062248145544769054, 0.06545514039627437, 0.0668232641082078, 0.06691870717943053, 0.06798324738941867, 0.06920166378625643, 0.06992344417798535, 0.07320793475110504, 0.07485223201854446, 0.07507511174553223, 0.07533809404118634, 0.07566082464674438, 0.0765223189636236, 0.07739614721417978, 0.07867763866545584, 0.08007297882225252, 0.08031089188928417, 0.0816587811184197, 0.08558972509862865, 0.08579012099929985, 0.08602338209105449, 0.08604042433935806, 0.0864595200077023, 0.08716473559730094, 0.08772612329504363, 0.09215192847245376, 0.09234231814064278, 0.09242959541014271, 0.0933500829476533, 0.0935190650233831, 0.09691560301481193, 0.09693083031588527, 0.10032731529930222, 0.10044543602172727, 0.10075582797385392, 0.10077300443866985, 0.10202455547041278, 0.11086721357455044, 0.1135965082231094, 0.11449418748023107, 0.11543329377300326, 0.1156882686862246, 0.11764829967695406, 0.11924472451553551, 0.11944180129315932, 0.12103974434564287, 0.12131556244948656, 0.12289676913670917, 0.12444129607089091, 0.12460631611006068, 0.12478826384293215]\n",
      "distances.shape: (150, 90)\n",
      "P:\n",
      "  (0, 66)\t1.644211828413447e-79\n",
      "  (0, 73)\t6.320943642009917e-79\n",
      "  (0, 63)\t9.725993125500299e-79\n",
      "  (0, 60)\t3.134065931027524e-76\n",
      "  (0, 78)\t1.0194662455936151e-75\n",
      "  (0, 76)\t1.1504971447162314e-75\n",
      "  (0, 89)\t6.925139567692208e-75\n",
      "  (0, 54)\t8.91200861000397e-75\n",
      "  (0, 94)\t1.715657183251806e-74\n",
      "  (0, 62)\t1.952687594365982e-74\n",
      "  (0, 91)\t1.0710476884895005e-73\n",
      "  (0, 59)\t1.0583044270414619e-72\n",
      "  (0, 52)\t2.3456287083712483e-71\n",
      "  (0, 56)\t3.237101256660127e-70\n",
      "  (0, 58)\t3.295766786035955e-69\n",
      "  (0, 80)\t7.293818441961707e-69\n",
      "  (0, 96)\t1.6006238651010247e-68\n",
      "  (0, 86)\t1.7848944560805378e-68\n",
      "  (0, 69)\t4.933689090586955e-68\n",
      "  (0, 99)\t7.539200820057066e-68\n",
      "  (0, 92)\t2.335667726964152e-67\n",
      "  (0, 85)\t3.8186273075812034e-67\n",
      "  (0, 61)\t1.4377147462162716e-66\n",
      "  (0, 67)\t1.3295599345473201e-65\n",
      "  (0, 97)\t2.003759904408844e-65\n",
      "  :\t:\n",
      "  (149, 66)\t0.00010821716560473816\n",
      "  (149, 148)\t0.0001600242818745115\n",
      "  (149, 115)\t0.0001291669307518397\n",
      "  (149, 110)\t0.00011524701761055908\n",
      "  (149, 104)\t0.00012856532161365652\n",
      "  (149, 83)\t0.00012040932708944288\n",
      "  (149, 84)\t0.0002055848812741093\n",
      "  (149, 131)\t0.00011763059722888982\n",
      "  (149, 147)\t0.00011694589035476711\n",
      "  (149, 70)\t0.00020501603643885774\n",
      "  (149, 120)\t0.00013433806583105438\n",
      "  (149, 103)\t0.0001806944850043868\n",
      "  (149, 106)\t0.00024431485406393874\n",
      "  (149, 121)\t0.0002153356856310271\n",
      "  (149, 138)\t0.000217025785934713\n",
      "  (149, 142)\t0.00020174701513727062\n",
      "  (149, 101)\t0.00020174701513727062\n",
      "  (149, 143)\t0.0001990463518830396\n",
      "  (149, 116)\t0.00022701832157158148\n",
      "  (149, 127)\t0.00023832436909330514\n",
      "  (149, 109)\t0.0002552900073148653\n",
      "  (149, 137)\t0.00044480393097952043\n",
      "  (149, 117)\t0.0005240028443040473\n",
      "  (149, 124)\t0.0005603109144443751\n",
      "  (149, 149)\t0.0006910949474297862\n",
      "\n",
      "knn_index:\n",
      "<__main__.NearPy object at 0x11ca302b0>\n"
     ]
    }
   ],
   "source": [
    "affinities_train = MultiANNPerplexityBasedNN(\n",
    "    x,\n",
    "    perplexity=30,\n",
    "    method=\"nearpy\",\n",
    "    metric=\"euclidean\",\n",
    "    n_jobs=8,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "#possible solution\n",
    "#affinities_train.knn_index = stelmach.build_knn_index()\n",
    "\n",
    "print(\"P:\")\n",
    "print(affinities_train.P)\n",
    "print(\"\")\n",
    "\n",
    "#print(\"data:\")\n",
    "#print(affinities_train.data)\n",
    "#print(\"\")\n",
    "\n",
    "print(\"knn_index:\")\n",
    "print(affinities_train.knn_index)\n",
    "\n",
    "#print(\".index\")\n",
    "#print(affinities_train.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape: (150, 4)\n",
      "\n",
      "Performing indexing with multiple binary hashes...\n",
      "Indexing took 0.157069 seconds\n",
      "\n",
      "Neighbour distances with multiple binary hashes:\n",
      "query: [5.1 3.5 1.4 0.2]\n",
      "  -> Candidate count is 2265\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "neighbours() got an unexpected keyword argument 'vector_filter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-33f215456c1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;31m##########################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m \u001b[0mexample2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-60-33f215456c1e>\u001b[0m in \u001b[0;36mexample2\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"query: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'  -> Candidate count is %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mengine_rbps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcandidate_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine_rbps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvector_filter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_filter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Results: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mneigh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: neighbours() got an unexpected keyword argument 'vector_filter'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Copyright (c) 2013 Ole Krause-Sparmann\n",
    "\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "\n",
    "# The above copyright notice and this permission notice shall be included in\n",
    "# all copies or substantial portions of the Software.\n",
    "\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    "# THE SOFTWARE.\n",
    "\n",
    "import numpy\n",
    "import scipy\n",
    "import unittest\n",
    "import time\n",
    "\n",
    "from nearpy import Engine\n",
    "from nearpy.distances import CosineDistance, EuclideanDistance\n",
    "\n",
    "from nearpy.hashes import RandomBinaryProjections, HashPermutations, HashPermutationMapper\n",
    "\n",
    "\n",
    "from nearpy.filters import NearestFilter\n",
    "\n",
    "def example2(data):\n",
    "    print(\"data.shape: {}\".format(data.shape))\n",
    "    # Dimension of feature space\n",
    "    DIM = data.shape[1]\n",
    "\n",
    "    # Number of data points (dont do too much because of exact search)\n",
    "    POINTS = data.shape[0]\n",
    "\n",
    "    _filter = NearestFilter(20)\n",
    "    #######\n",
    "\n",
    "    print('\\nPerforming indexing with multiple binary hashes...')\n",
    "    t0 = time.time()\n",
    "\n",
    "    hashes = []\n",
    "    for k in range(30):\n",
    "        hashes.append(RandomBinaryProjections('rbp_%d' % k, 10))\n",
    "\n",
    "    # Create engine\n",
    "    engine_rbps = Engine(DIM, lshashes=hashes, distance=EuclideanDistance())\n",
    "\n",
    "    # First index some random vectors\n",
    "    #matrix = numpy.zeros((POINTS,DIM))\n",
    "    matrix = numpy.asarray(data)\n",
    "    #print(matrix)\n",
    "    #for i in range(POINTS):\n",
    "        #v = numpy.random.randn(DIM)\n",
    "        #matrix[i] = v\n",
    "    #    engine_rbps.store_vector(matrix[i])\n",
    "    for i, x in enumerate(data):\n",
    "        engine_rbps.store_vector(x, i)\n",
    "\n",
    "    t1 = time.time()\n",
    "    print('Indexing took %f seconds' % (t1-t0))\n",
    "\n",
    "    # Get random query vector\n",
    "    query = matrix[0]\n",
    "    # Do random query on engine 4\n",
    "    print('\\nNeighbour distances with multiple binary hashes:')\n",
    "    print(\"query: {}\".format(query))\n",
    "    print('  -> Candidate count is %d' % engine_rbps.candidate_count(query))\n",
    "    results = engine_rbps.neighbours(query,vector_filter=[_filter])\n",
    "    print('Results: {}'.format(results))\n",
    "    neigh = [x[1] for x in results]\n",
    "    dists = [x[2] for x in results]\n",
    "    print(neigh, dists)\n",
    "\n",
    "    # Real neighbours\n",
    "    #print('\\nReal neighbour distances:')\n",
    "    #print(\"1. Query: {}\".format(query))\n",
    "    #query = query.reshape((DIM))\n",
    "    #print(\"2. Query: {}\".format(query))\n",
    "    #print(\"0. dists: {}\".format(dists))\n",
    "    #dists = EuclideanDistance().distance(matrix,query)\n",
    "    #print(\"2. cosineDistance dists: {}\".format(dists))\n",
    "    #dists = dists.reshape((-1,))\n",
    "    #print(\"3. reshape dists: {}\".format(dists))\n",
    "    #dists = sorted(dists)\n",
    "    #print(\"4. sorted dists: {}\".format(dists))\n",
    "    #print(len(dists))\n",
    "    #print(len(dists[0]))\n",
    "    #print(dists[:30])\n",
    "\n",
    "    \n",
    "    #print(engine_rbps._get_candidates(matrix[0]))\n",
    "    ##########################################################\n",
    "    \n",
    "example2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Copyright (c) 2013 Ole Krause-Sparmann\n",
    "\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "\n",
    "# The above copyright notice and this permission notice shall be included in\n",
    "# all copies or substantial portions of the Software.\n",
    "\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    "# THE SOFTWARE.\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy\n",
    "import scipy\n",
    "import time\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from nearpy.utils import numpy_array_from_list_or_numpy_array\n",
    "from nearpy.utils.utils import unitvec\n",
    "\n",
    "\n",
    "class RecallPrecisionExperiment(object):\n",
    "    \"\"\"\n",
    "    Performs nearest neighbour recall experiments with custom vector data\n",
    "    for all engines in the specified list.\n",
    "    perform_experiment() returns list of (recall, precision, search_time)\n",
    "    tuple. These are the averaged values over all request vectors. search_time\n",
    "    is the average retrieval/search time compared to the average exact search\n",
    "    time.\n",
    "    coverage_ratio determines how many of the vectors are used as query\n",
    "    vectors for exact andapproximated search. Because the search comparance\n",
    "    overhead is quite large, it is best with large data sets (>10000) to\n",
    "    use a low coverage_ratio (like 0.1) to make the experiment fast. A\n",
    "    coverage_ratio of 0.1 makes the experiment use 10% of all the vectors\n",
    "    for querying, that is, it looks for 10% of all vectors for the nearest\n",
    "    neighbours.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, N, vectors, coverage_ratio=0.2):\n",
    "        \"\"\"\n",
    "        Performs exact nearest neighbour search on the data set.\n",
    "        vectors can either be a numpy matrix with all the vectors\n",
    "        as columns OR a python array containing the individual\n",
    "        numpy vectors.\n",
    "        \"\"\"\n",
    "        # We need a dict from vector string representation to index\n",
    "        self.vector_dict = {}\n",
    "        self.N = N\n",
    "        print(\"N: {}\".format(N))\n",
    "        self.coverage_ratio = coverage_ratio\n",
    "        self.vectors = numpy_array_from_list_or_numpy_array(vectors)\n",
    "\n",
    "        # Get numpy array representation of input\n",
    "        #self.vectors = numpy.vstack([unitvec(v) for v in numpy_vectors.T])\n",
    "        #print(self.vectors)\n",
    "        print(len(self.vectors))\n",
    "        ## Build map from vector string representation to vector\n",
    "        for index, v in enumerate(self.vectors):\n",
    "            self.vector_dict[self.__vector_to_string(v)] = index\n",
    "        \n",
    "        # Determine the indices of query vectors used for comparance\n",
    "        # with approximated search.\n",
    "        query_count = numpy.floor(self.coverage_ratio *\n",
    "                                  len(self.vectors))\n",
    "        print(query_count)\n",
    "        self.query_indices = []\n",
    "        for k in range(int(query_count)):\n",
    "            index = numpy.floor(k * (float(len(self.vectors)) / query_count))\n",
    "            index = min(index, len(self.vectors) - 1)\n",
    "            self.query_indices.append(int(index))\n",
    "\n",
    "        print('\\nStarting exact search (query set size=%d)...\\n' % query_count)\n",
    "\n",
    "        # For each query vector get the closest N neighbours\n",
    "        self.closest = {}\n",
    "        self.exact_search_time_per_vector = 0.0\n",
    "\n",
    "        for index in self.query_indices:\n",
    "            v = self.vectors[index, numpy.newaxis]\n",
    "            exact_search_start_time = time.time()\n",
    "            D = cdist(v, self.vectors, 'euclidean')\n",
    "            self.closest[index] = scipy.argsort(D)[0, 1:N+1]\n",
    "\n",
    "            # Save time needed for exact search\n",
    "            exact_search_time = time.time() - exact_search_start_time\n",
    "            self.exact_search_time_per_vector += exact_search_time\n",
    "\n",
    "        print('Done with exact search...\\n')\n",
    "\n",
    "        # Normalize search time\n",
    "        self.exact_search_time_per_vector /= float(len(self.query_indices))\n",
    "\n",
    "    def perform_experiment(self, engine_list):\n",
    "        \"\"\"\n",
    "        Performs nearest neighbour recall experiments with custom vector data\n",
    "        for all engines in the specified list.\n",
    "        Returns self.result contains list of (recall, precision, search_time)\n",
    "        tuple. All are the averaged values over all request vectors.\n",
    "        search_time is the average retrieval/search time compared to the\n",
    "        average exact search time.\n",
    "        \"\"\"\n",
    "        # We will fill this array with measures for all the engines.\n",
    "        result = []\n",
    "\n",
    "        # For each engine, first index vectors and then retrieve neighbours\n",
    "        for endine_idx, engine in enumerate(engine_list):\n",
    "            print('Engine %d / %d' % (endine_idx, len(engine_list)))\n",
    "\n",
    "            # Clean storage\n",
    "            engine.clean_all_buckets()\n",
    "            # Use this to compute average recall\n",
    "            avg_recall = 0.0\n",
    "            # Use this to compute average precision\n",
    "            avg_precision = 0.0\n",
    "            # Use this to compute average search time\n",
    "            avg_search_time = 0.0\n",
    "\n",
    "            # Index all vectors and store them\n",
    "            for index, v in enumerate(self.vectors):\n",
    "                engine.store_vector(v, 'data_%d' % index)\n",
    "\n",
    "            # Look for N nearest neighbours for query vectors\n",
    "            for index in self.query_indices:\n",
    "                # Get indices of the real nearest as set\n",
    "                real_nearest = set(self.closest[index])\n",
    "                print(\"Get indices of the real nearest as set: {}\".format(len(real_nearest)))\n",
    "                # We have to time the search\n",
    "                search_time_start = time.time()\n",
    "\n",
    "                # Get nearest N according to engine\n",
    "                nearest = engine.neighbours(self.vectors[index])\n",
    "                print(\"Get nearest N according to engine: {}\".format(len(nearest)))\n",
    "                # Get search time\n",
    "                search_time = time.time() - search_time_start\n",
    "\n",
    "                # For comparance we need their indices (as set)\n",
    "                nearest = set([self.__index_of_vector(x[0]) for x in nearest])\n",
    "\n",
    "                # Remove query index from search result to make sure that\n",
    "                # recall and precision make sense in terms of \"neighbours\".\n",
    "                # If ONLY the query vector is retrieved, we want recall to be\n",
    "                # zero!\n",
    "                nearest.remove(index)\n",
    "\n",
    "                # If the result list is empty, recall and precision are 0.0\n",
    "                if len(nearest) == 0:\n",
    "                    recall = 0.0\n",
    "                    precision = 0.0\n",
    "                else:\n",
    "                    # Get intersection count\n",
    "                    inter_count = float(len(real_nearest & nearest))\n",
    "\n",
    "                    # Normalize recall for this vector\n",
    "                    recall = inter_count/float(len(real_nearest))\n",
    "\n",
    "                    # Normalize precision for this vector\n",
    "                    precision = inter_count/float(len(nearest))\n",
    "\n",
    "                # Add to accumulator\n",
    "                avg_recall += recall\n",
    "\n",
    "                # Add to accumulator\n",
    "                avg_precision += precision\n",
    "\n",
    "                # Add to accumulator\n",
    "                avg_search_time += search_time\n",
    "\n",
    "            # Normalize recall over query set\n",
    "            avg_recall /= float(len(self.query_indices))\n",
    "\n",
    "            # Normalize precision over query set\n",
    "            avg_precision /= float(len(self.query_indices))\n",
    "\n",
    "            # Normalize search time over query set\n",
    "            avg_search_time = avg_search_time / float(len(self.query_indices))\n",
    "\n",
    "            # Normalize search time with respect to exact search\n",
    "            avg_search_time /= self.exact_search_time_per_vector\n",
    "\n",
    "            print('  recall=%f, precision=%f, time=%f' % (avg_recall,\n",
    "                                                          avg_precision,\n",
    "                                                          avg_search_time))\n",
    "\n",
    "            result.append((avg_recall, avg_precision, avg_search_time))\n",
    "\n",
    "        # Return (recall, precision, search_time) tuple\n",
    "        return result\n",
    "\n",
    "    def __vector_to_string(self, vector):\n",
    "        \"\"\" Returns string representation of vector. \"\"\"\n",
    "        return numpy.array_str(numpy.round(unitvec(vector), decimals=3))\n",
    "\n",
    "    def __index_of_vector(self, vector):\n",
    "        \"\"\" Returns index of specified vector from test data set. \"\"\"\n",
    "        return self.vector_dict[self.__vector_to_string(vector)]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_engine(data): \n",
    "        n_items, vector_length = data.shape\n",
    "        #print(data)\n",
    "        #parameters init\n",
    "        method_param = init_method_param(\"nearpy\")\n",
    "        filter = NearestFilter(10)\n",
    "        \n",
    "        hashes = []\n",
    "        for k in range(method_param[\"hash_counts\"]):\n",
    "            nearpy_rbp = nearpy.hashes.RandomBinaryProjections(\n",
    "                'rbp_%d' % k, method_param[\"n_bits\"])\n",
    "            hashes.append(nearpy_rbp)\n",
    "        metric = \"euclidean\"\n",
    "        if metric == 'euclidean':\n",
    "            dist = nearpy.distances.EuclideanDistance()\n",
    "            index = nearpy.Engine(\n",
    "                vector_length,\n",
    "                lshashes=hashes,\n",
    "                distance=dist)\n",
    "        else:  # Default (angular) = Cosine distance\n",
    "            index = nearpy.Engine(\n",
    "                vector_length,\n",
    "                lshashes=hashes,\n",
    "                vector_filters=[self.filter])\n",
    "            \n",
    "        return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 90\n",
      "150\n",
      "30.0\n",
      "\n",
      "Starting exact search (query set size=30)...\n",
      "\n",
      "Done with exact search...\n",
      "\n",
      "Engine 0 / 1\n",
      "Get indices of the real nearest as set: 90\n",
      "Get nearest N according to engine: 10\n",
      "Get indices of the real nearest as set: 90\n",
      "Get nearest N according to engine: 10\n",
      "Get indices of the real nearest as set: 90\n",
      "Get nearest N according to engine: 10\n",
      "Get indices of the real nearest as set: 90\n",
      "Get nearest N according to engine: 10\n",
      "Get indices of the real nearest as set: 90\n",
      "Get nearest N according to engine: 10\n",
      "Get indices of the real nearest as set: 90\n",
      "Get nearest N according to engine: 10\n",
      "Get indices of the real nearest as set: 90\n",
      "Get nearest N according to engine: 10\n",
      "Get indices of the real nearest as set: 90\n",
      "Get nearest N according to engine: 10\n",
      "Get indices of the real nearest as set: 90\n",
      "Get nearest N according to engine: 10\n",
      "Get indices of the real nearest as set: 90\n",
      "Get nearest N according to engine: 10\n",
      "Get indices of the real nearest as set: 90\n",
      "Get nearest N according to engine: 10\n",
      "Get indices of the real nearest as set: 90\n",
      "Get nearest N according to engine: 10\n",
      "Get indices of the real nearest as set: 90\n",
      "Get nearest N according to engine: 10\n",
      "Get indices of the real nearest as set: 90\n",
      "Get nearest N according to engine: 10\n",
      "Get indices of the real nearest as set: 90\n",
      "Get nearest N according to engine: 10\n",
      "Get indices of the real nearest as set: 90\n",
      "Get nearest N according to engine: 10\n",
      "Get indices of the real nearest as set: 90\n",
      "Get nearest N according to engine: 10\n",
      "Get indices of the real nearest as set: 90\n",
      "Get nearest N according to engine: 10\n",
      "Get indices of the real nearest as set: 90\n",
      "Get nearest N according to engine: 10\n",
      "Get indices of the real nearest as set: 90\n",
      "Get nearest N according to engine: 10\n",
      "Get indices of the real nearest as set: 90\n",
      "Get nearest N according to engine: 10\n",
      "Get indices of the real nearest as set: 90\n",
      "Get nearest N according to engine: 10\n",
      "Get indices of the real nearest as set: 90\n",
      "Get nearest N according to engine: 10\n",
      "Get indices of the real nearest as set: 90\n",
      "Get nearest N according to engine: 10\n",
      "Get indices of the real nearest as set: 90\n",
      "Get nearest N according to engine: 10\n",
      "Get indices of the real nearest as set: 90\n",
      "Get nearest N according to engine: 10\n",
      "Get indices of the real nearest as set: 90\n",
      "Get nearest N according to engine: 10\n",
      "Get indices of the real nearest as set: 90\n",
      "Get nearest N according to engine: 10\n",
      "Get indices of the real nearest as set: 90\n",
      "Get nearest N according to engine: 10\n",
      "Get indices of the real nearest as set: 90\n",
      "Get nearest N according to engine: 10\n",
      "  recall=0.097778, precision=0.977778, time=32.542120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.0977777777777778, 0.9777777777777779, 32.542120408508715)]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(x)\n",
    "#print(x.shape)\n",
    "init = RecallPrecisionExperiment(90, x, 0.9)\n",
    "\n",
    "engine = build_engine(x)\n",
    "init.perform_experiment([engine])\n",
    "#\n",
    "#        __init__(self, N, vectors, coverage_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.68367934  0.4976707 ]\n",
      "[(array([-0.95665394,  0.29122712]), 'data_38', 3.286715308148391e-05), (array([-0.96197981,  0.27312056]), 'data_118', 5.7954759213441065e-05), (array([-0.95090124,  0.30949447]), 'data_50', 0.0003715234882036844), (array([-0.96908529,  0.24672597]), 'data_28', 0.000725766565274788), (array([-0.9381949,  0.3461074]), 'data_137', 0.0021783483999329167), (array([-0.93341192,  0.35880663]), 'data_24', 0.003165410069035701), (array([-0.9312681 ,  0.36433464]), 'data_45', 0.0036543181386105017), (array([-0.98014272,  0.19829333]), 'data_14', 0.0038506514393582547), (array([-0.98996828,  0.14128976]), 'data_74', 0.010586408235638833), (array([-0.90752389,  0.42000045]), 'data_69', 0.010645512652042166)]\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "from nearpy import Engine\n",
    "from nearpy.hashes import RandomBinaryProjections\n",
    "\n",
    "# Dimension of our vector space\n",
    "dimension = 2\n",
    "\n",
    "# Create a random binary hash with 10 bits\n",
    "rbp = RandomBinaryProjections('rbp', 10)\n",
    "\n",
    "# Create engine with pipeline configuration\n",
    "engine = Engine(dimension, lshashes=[rbp])\n",
    "\n",
    "# Index 1000000 random vectors (set their data to a unique string)\n",
    "for index in range(150):\n",
    "    v = numpy.random.randn(dimension)\n",
    "    engine.store_vector(v, 'data_%d' % index)\n",
    "\n",
    "# Create random query vector\n",
    "query = numpy.random.randn(dimension)\n",
    "\n",
    "# Get nearest neighbours\n",
    "N = engine.neighbours(query)\n",
    "print(query)\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONNG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from __future__ import absolute_import\n",
    "import ngtpy\n",
    "import numpy as np\n",
    "\n",
    "class ONNG(KNNIndex):\n",
    "    #VALID_METRICS = neighbors.ONNG.valid_metrics\n",
    "    \n",
    "    def build(self, data):\n",
    "        #metrics = {'euclidean': '2', 'angular': 'C'}\n",
    "        self._metric = metrics[metric]\n",
    "        self._object_type\n",
    "        self._edge_size_for_search = -2\n",
    "        self._build_time_limit = 4\n",
    "        self._epsilon = epsilon\n",
    "        if self.method_param == None:\n",
    "            self.method_param['edge'] == 0.0\n",
    "            self.method_param['outdegree'] == 0.0\n",
    "            self.method_param['indegree'] == 0.0\n",
    "\n",
    "        dim = len(data[0])\n",
    "        index_dir = 'indexes'\n",
    "        if not os.path.exists(index_dir):\n",
    "            os.makedirs(index_dir)\n",
    "        index = os.path.join(\n",
    "            index_dir,\n",
    "            'ONNG-{}-{}-{}'.format(self._edge_size, self._outdegree,\n",
    "                                   self._indegree))\n",
    "        anngIndex = os.path.join(index_dir, 'ANNG-' + str(self._edge_size))\n",
    "        if (not os.path.exists(index)) and (not os.path.exists(anngIndex)):\n",
    "            t = time.time()\n",
    "            args = ['ngt', 'create', '-it', '-p8', '-b500', '-ga', '-of',\n",
    "                    '-D' + self._metric, '-d' + str(dim),\n",
    "                    '-E' + str(self._edge_size), '-S0',\n",
    "                    '-e' + str(self._epsilon), '-P0', '-B30',\n",
    "                    '-T' + str(self._build_time_limit), anngIndex]\n",
    "            subprocess.call(args)\n",
    "            idx = ngtpy.Index(path=anngIndex)\n",
    "            idx.batch_insert(X, num_threads=24, debug=False)\n",
    "            idx.save()\n",
    "            idx.close()\n",
    "        if not os.path.exists(index):\n",
    "            t = time.time()\n",
    "            args = ['ngt', 'reconstruct-graph', '-mS',\n",
    "                    '-o ' + str(self._outdegree),\n",
    "                    '-i ' + str(self._indegree), anngIndex, index]\n",
    "            subprocess.call(args)\n",
    "        if os.path.exists(index):\n",
    "            t = time.time()\n",
    "            self.index = ngtpy.Index(index, read_only=True)\n",
    "            self.indexName = index\n",
    "        else:\n",
    "            print('ONNG: Problem.')\n",
    "        \n",
    "            \n",
    "    def query_train(self, data, k):    \n",
    "        neighbors, distances = self.index.search(\n",
    "            v, k, self._epsilon, self._edge_size_for_search,\n",
    "            with_distance=False)\n",
    "        return neighbors, distances\n",
    "        \n",
    "        \n",
    "    def query(self, query, k):\n",
    "        #check in what format results are, get neighbors, distances\n",
    "        neighbors, distances = self.index.search(\n",
    "            v, k, self._epsilon, self._edge_size_for_search,\n",
    "            with_distance=False)\n",
    "        return neighbors, distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FLANN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FLANN(KNNIndex):\n",
    "    #VALID_METRICS = neighbors.Flann.valid_metrics\n",
    "    \n",
    "    def build(self, data):\n",
    "        #parameters init\n",
    "        if self.method_param == None:\n",
    "            self.method_param = {}\n",
    "            self.method_param['target_precision'] = 0.9  # want 90% target precision  \n",
    "        self._metric = metric\n",
    "        \n",
    "        self.index = pyflann.FLANN(\n",
    "            target_precision=self._target_precision,\n",
    "            algorithm='autotuned', \n",
    "            log_level='info')\n",
    "        if self._metric == 'angular':\n",
    "            data = sklearn.preprocessing.normalize(data, axis=1, norm='l2')\n",
    "        self.index.build_index(data)\n",
    "\n",
    "\n",
    "###### \n",
    "    def query_train(self, data, k):\n",
    "        if self._metric == 'angular':\n",
    "            v = sklearn.preprocessing.normalize([v], axis=1, norm='l2')[0]\n",
    "        if v.dtype != numpy.float32:\n",
    "            v = v.astype(numpy.float32)\n",
    "        return self._flann.nn_index(v, n)[0][0]\n",
    "\n",
    "    def query(self, query, k):\n",
    "        if self._metric == 'angular':\n",
    "            v = sklearn.preprocessing.normalize([v], axis=1, norm='l2')[0]\n",
    "        if v.dtype != numpy.float32:\n",
    "            v = v.astype(numpy.float32)\n",
    "        return self._flann.nn_index(v, n)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RPForest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpforest\n",
    "import numpy\n",
    "\n",
    "\n",
    "class RPForest(KNNIndex):\n",
    "    #VALID_METRICS = neighbors.Annoy.valid_metrics\n",
    "    \n",
    "    def build(self, data):\n",
    "        n_trees = 5 + int(round((data.shape[0]) ** 0.5 / 20))\n",
    "        #n_iters = max(5, int(round(np.log2(data.shape[0]))))\n",
    "        leaf_size = ?\n",
    "        \n",
    "        self.index = rpforest.RPForest(leaf_size=leaf_size, no_trees=n_trees)\n",
    "        \n",
    "        #if data.dtype != numpy.double:\n",
    "        #    data = numpy.array(data).astype(numpy.double)\n",
    "        self.index.fit(data)\n",
    "\n",
    "    def query_train(self, data, k):\n",
    "        neighbors, distances = self._model.query(data[0], k)\n",
    "        return neighbors, distances\n",
    "\n",
    "    def query(self, query, k):\n",
    "        neighbors, distances = self._model.query(data[0], k)\n",
    "        return neighbors, distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hnswlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "import hnswlib\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class HnswLib(KNNIndex):\n",
    "    #VALID_METRICS = neighbors.Annoy.valid_metrics\n",
    "    \n",
    "    def build(self,data):  \n",
    "        #parameter init\n",
    "        #self.metric = {'angular': 'cosine', 'euclidean': 'l2'}[metric]\n",
    "        if self.method_param == None:\n",
    "            self.method_param = {}\n",
    "            self.method_param[\"efConstruction\"] = 200\n",
    "            self.method_param[\"M\"] = 16\n",
    "            self.method_param[\"efRecall\"] = 10\n",
    "            #self.name = 'hnswlib (%s)' % (self.method_param)\n",
    "        \n",
    "        \n",
    "        self.index = hnswlib.Index(space=self.metric, dim=len(data[0]))\n",
    "        self.index.init_index(max_elements=len(data),\n",
    "                          ef_construction=self.method_param[\"efConstruction\"],\n",
    "                          M=self.method_param[\"M\"])\n",
    "        data_labels = np.arange(len(data))\n",
    "        self.index.add_items(np.asarray(data), data_labels)\n",
    "        self.index.set_num_threads(self.n_jobs)\n",
    "        self.index.set_ef(self.method_param[\"efRecall\"])\n",
    "\n",
    "    def query(self, query, k):\n",
    "        neighbors, distances = self.index.knn_query(query, k=k)\n",
    "        return neighbors, distances\n",
    "    \n",
    "    def query_train(self, data, k):\n",
    "        neighbors, distances = self.index.knn_query(data, k=k)\n",
    "        return neighbors, distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annoy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openTSNE.nearest_neighbors import KNNIndex\n",
    "import annoy\n",
    "import numpy as np\n",
    "\n",
    "class Annoy(KNNIndex):\n",
    "    #VALID_METRICS = neighbors.Annoy.valid_metrics\n",
    "    \n",
    "    def build(self, data):\n",
    "        n_items, vector_length = data.shape\n",
    "        #initalize parameters\n",
    "        method_param = init_method_param(\"annoy\", data)\n",
    "        #build index\n",
    "        self.index = annoy.AnnoyIndex(vector_length, metric=self.metric)\n",
    "        for i in range(n_items):\n",
    "            self.index.add_item(i, data[i])\n",
    "        self.index.build(method_param[\"ntrees\"])\n",
    "        \n",
    "    def query_train(self, data, k):\n",
    "        #add search_k parameter: tradeoff between speed and accuracy?\n",
    "        #neighbors_single, distances_single = np.asarray(self.index.get_nns_by_vector(data[i], n=k, search_k=-1, include_distances=True))\n",
    "        #output array with points x neighbors:\n",
    "        neighbors = np.empty((data.shape[0],k), dtype=int)\n",
    "        distances = np.empty((data.shape[0],k))\n",
    "        for i in range(len(data)):\n",
    "            neighbors_single, distances_single = np.asarray(self.index.get_nns_by_item(i, n=k, search_k=-1 ,include_distances=True))\n",
    "            neighbors[i] = neighbors_single\n",
    "            distances[i] = distances_single\n",
    "        print(\"neighbors.shape: {}\".format(neighbors.shape))\n",
    "        print(\"neighbors[0]: {}\".format(neighbors[0]))\n",
    "        print(neighbors.shape)\n",
    "        print(\"distances.shape: {}\".format(distances.shape))\n",
    "        print(\"distances[0]: {}\".format(distances[0]))\n",
    "        return neighbors, distances\n",
    "\n",
    "    def query(self, query, k):\n",
    "        neighbors = np.empty((query.shape[0],k), dtype=int)\n",
    "        distances = np.empty((query.shape[0],k))\n",
    "        for i in range(len(query)):\n",
    "            neighbors_single, distances_single = np.asarray(self.index.get_nns_by_vector(query[i], n=k, search_k=-1, include_distances=True))\n",
    "            neighbors[i] = neighbors_single\n",
    "            distances[i] = distances_single\n",
    "        return neighbors, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors.shape: (150, 90)\n",
      "neighbors[0]: [  0  17   4  28  27  39   7  40  49  37  21  48  26  19  46  11  35  10\n",
      "  31  36  20  34  43   9  23   2   6  30   1  29  25  16  47  12  24  45\n",
      "  44   5  32  22   3  18  42  33  38  14   8  13  15  41  98  57  93  79\n",
      "  64  81  60  80  69  59  82  88  67  92  89  99  95  71  53  96  62  94\n",
      "  61  90  97  84  55  74  66  85  78 106  91  75  51  87  65  73  63  58]\n",
      "(150, 90)\n",
      "distances.shape: (150, 90)\n",
      "distances[0]: [0.         0.10000001 0.14142123 0.14142123 0.1414213  0.1414213\n",
      " 0.17320499 0.17320505 0.2236068  0.24494879 0.30000004 0.30000022\n",
      " 0.31622773 0.33166245 0.36055511 0.37416551 0.37416565 0.37416592\n",
      " 0.38729846 0.41231066 0.43589005 0.45825756 0.45825759 0.46904159\n",
      " 0.46904165 0.509902   0.51961523 0.5385164  0.5385164  0.53851658\n",
      " 0.54772258 0.5477227  0.58309519 0.59160781 0.59160781 0.59160781\n",
      " 0.61644137 0.61644155 0.62449968 0.64807403 0.64807415 0.74161977\n",
      " 0.76811439 0.80622566 0.86602527 0.88317627 0.92195427 0.99498719\n",
      " 1.10453606 1.34907377 2.09045458 2.34520769 2.38746715 2.49399257\n",
      " 2.5806973  2.70185137 2.70370102 2.81780052 2.88270712 2.88790584\n",
      " 2.89482307 2.99999976 3.0099833  3.0099833  3.0215888  3.05777693\n",
      " 3.074085   3.07571125 3.09354162 3.12569952 3.14642644 3.15277624\n",
      " 3.22800231 3.31209898 3.3451457  3.41174436 3.41613817 3.41613841\n",
      " 3.43511271 3.51994324 3.53128862 3.59165692 3.59583068 3.59722114\n",
      " 3.61662817 3.61801076 3.62767124 3.65786791 3.69999957 3.74966645]\n",
      "P:\n",
      "  (0, 58)\t1.1123856191126478e-48\n",
      "  (0, 63)\t1.629381818051472e-47\n",
      "  (0, 73)\t1.5443295993298925e-46\n",
      "  (0, 65)\t7.618908252567122e-46\n",
      "  (0, 87)\t1.2659956581135655e-45\n",
      "  (0, 51)\t1.361279451433849e-45\n",
      "  (0, 75)\t3.7587606280968164e-45\n",
      "  (0, 91)\t4.041633163961909e-45\n",
      "  (0, 106)\t5.024286834345004e-45\n",
      "  (0, 78)\t1.1373116778461108e-43\n",
      "  (0, 85)\t2.0320429640373955e-43\n",
      "  (0, 66)\t1.4684333760073635e-41\n",
      "  (0, 74)\t3.770849500982889e-41\n",
      "  (0, 55)\t3.7708940636562237e-41\n",
      "  (0, 84)\t4.687778032095442e-41\n",
      "  (0, 97)\t1.2268324422718476e-39\n",
      "  (0, 90)\t6.052593783026402e-39\n",
      "  (0, 61)\t3.2721531985417874e-37\n",
      "  (0, 94)\t1.0645757646313081e-35\n",
      "  (0, 62)\t1.4229865461859848e-35\n",
      "  (0, 96)\t3.654254097655959e-35\n",
      "  (0, 53)\t1.55931299641511e-34\n",
      "  (0, 71)\t3.463470407810223e-34\n",
      "  (0, 95)\t3.724106684873443e-34\n",
      "  (0, 99)\t7.692885885901127e-34\n",
      "  :\t:\n",
      "  (149, 66)\t7.330878315897751e-05\n",
      "  (149, 116)\t7.599730076727377e-05\n",
      "  (149, 78)\t7.033520848381596e-05\n",
      "  (149, 56)\t0.00010558619198568894\n",
      "  (149, 91)\t8.089484542949024e-05\n",
      "  (149, 110)\t0.00010514943370423587\n",
      "  (149, 146)\t0.00012319205315800593\n",
      "  (149, 137)\t0.00012026321604423454\n",
      "  (149, 103)\t0.00013056033586095764\n",
      "  (149, 114)\t0.00021544346852801004\n",
      "  (149, 147)\t0.0001061385506654824\n",
      "  (149, 111)\t0.00012617327534216203\n",
      "  (149, 63)\t0.00011659041473327155\n",
      "  (149, 113)\t0.0002226519553219883\n",
      "  (149, 133)\t0.00019368156378631995\n",
      "  (149, 123)\t0.00018253938249201694\n",
      "  (149, 126)\t0.0002449212382791976\n",
      "  (149, 121)\t0.0003351397451320423\n",
      "  (149, 83)\t0.0003792148904964361\n",
      "  (149, 70)\t0.0004211395245416383\n",
      "  (149, 142)\t0.0004301334718734168\n",
      "  (149, 101)\t0.0004301334718734168\n",
      "  (149, 138)\t0.0004307341317329757\n",
      "  (149, 127)\t0.00046861379804921465\n",
      "  (149, 149)\t0.00069446280453884\n",
      "\n",
      "knn_index:\n",
      "<__main__.Annoy object at 0x125ba7908>\n"
     ]
    }
   ],
   "source": [
    "affinities_train = MultiANNPerplexityBasedNN(\n",
    "    x,\n",
    "    perplexity=30,\n",
    "    method=\"annoy\",\n",
    "    metric=\"euclidean\",\n",
    "    n_jobs=8,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "#possible solution\n",
    "#affinities_train.knn_index = stelmach.build_knn_index()\n",
    "\n",
    "print(\"P:\")\n",
    "print(affinities_train.P)\n",
    "print(\"\")\n",
    "\n",
    "#print(\"data:\")\n",
    "#print(affinities_train.data)\n",
    "#print(\"\")\n",
    "\n",
    "print(\"knn_index:\")\n",
    "print(affinities_train.knn_index)\n",
    "\n",
    "#print(\".index\")\n",
    "#print(affinities_train.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "affinities_train = MultiANNPerplexityBasedNN(\n",
    "    x,\n",
    "    perplexity=30,\n",
    "    method=\"approx\",\n",
    "    metric=\"euclidean\",\n",
    "    n_jobs=8,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "#possible solution\n",
    "#affinities_train.knn_index = stelmach.build_knn_index()\n",
    "\n",
    "print(\"P:\")\n",
    "print(affinities_train.P)\n",
    "print(\"\")\n",
    "\n",
    "#print(\"data:\")\n",
    "#print(affinities_train.data)\n",
    "#print(\"\")\n",
    "\n",
    "print(\"knn_index:\")\n",
    "print(affinities_train.knn_index)\n",
    "\n",
    "#print(\".index\")\n",
    "#print(affinities_train.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Generate initial coordinates for our embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.76 ms, sys: 1.44 ms, total: 3.2 ms\n",
      "Wall time: 10.9 ms\n"
     ]
    }
   ],
   "source": [
    "%time init_train = initialization.pca(x_train, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Construct the `TSNEEmbedding` object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 s, sys: 1e+03 ns, total: 4 s\n",
      "Wall time: 7.15 s\n",
      "(100, 4)\n",
      "90\n",
      "dp_n: [99, 30, 56, 44, 42, 89, 10, 1, 49, 67]\n",
      "neighbors.shape: (100, 10)\n",
      "dp_d: [0.0, 0.0019011171323550652, 0.0225228806620157, 0.028793654123802474, 0.02988671710970274, 0.03016191181211454, 0.03229629357291395, 0.03518415699213469, 0.036324830807021466, 0.036588578780322525]\n",
      "distances.shape: (100, 10)\n",
      "CPU times: user 4 s, sys: 1e+03 ns, total: 5 s\n",
      "Wall time: 10 s\n"
     ]
    }
   ],
   "source": [
    "%time \n",
    "affinities_train = MultiANNPerplexityBasedNN(\n",
    "    x_train,\n",
    "    perplexity=30,\n",
    "    method=\"nearpy\",\n",
    "    metric=\"euclidean\",\n",
    "    n_jobs=8,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "\n",
    "%time\n",
    "\n",
    "embedding_train = TSNEEmbedding(\n",
    "    init_train,\n",
    "    affinities_train,\n",
    "    negative_gradient_method=\"fft\",\n",
    "    n_jobs=8,\n",
    "    callbacks=ErrorLogger(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Optimize embedding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Early exaggeration phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration   50, KL divergence  2.0530, 50 iterations in 12.6337 sec\n",
      "Iteration  100, KL divergence  1.7041, 50 iterations in 1.6781 sec\n",
      "Iteration  150, KL divergence  1.9078, 50 iterations in 1.5947 sec\n",
      "Iteration  200, KL divergence  1.9569, 50 iterations in 2.1205 sec\n",
      "Iteration  250, KL divergence  2.0247, 50 iterations in 2.9188 sec\n",
      "CPU times: user 20.1 s, sys: 742 ms, total: 20.9 s\n",
      "Wall time: 21 s\n"
     ]
    }
   ],
   "source": [
    "%time embedding_train_1 = embedding_train.optimize(n_iter=250, exaggeration=12, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "utils.plot(embedding_train_1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration   50, KL divergence  0.4077, 50 iterations in 3.0244 sec\n",
      "Iteration  100, KL divergence  0.3013, 50 iterations in 3.0851 sec\n",
      "Iteration  150, KL divergence  0.2891, 50 iterations in 3.6652 sec\n",
      "Iteration  200, KL divergence  0.2892, 50 iterations in 4.2379 sec\n",
      "Iteration  250, KL divergence  0.2878, 50 iterations in 2.6357 sec\n",
      "Iteration  300, KL divergence  0.2786, 50 iterations in 3.7697 sec\n",
      "Iteration  350, KL divergence  0.3010, 50 iterations in 3.9746 sec\n",
      "Iteration  400, KL divergence  0.2693, 50 iterations in 4.3909 sec\n",
      "Iteration  450, KL divergence  0.2878, 50 iterations in 5.5242 sec\n",
      "Iteration  500, KL divergence  0.2903, 50 iterations in 6.3756 sec\n",
      "Iteration  550, KL divergence  0.3016, 50 iterations in 7.6603 sec\n",
      "Iteration  600, KL divergence  0.2985, 50 iterations in 10.8761 sec\n",
      "Iteration  650, KL divergence  0.3104, 50 iterations in 7.4258 sec\n",
      "Iteration  700, KL divergence  0.3018, 50 iterations in 6.4892 sec\n",
      "Iteration  750, KL divergence  0.3012, 50 iterations in 5.3151 sec\n",
      "CPU times: user 1min 15s, sys: 989 ms, total: 1min 16s\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%time embedding_train_2 = embedding_train_1.optimize(n_iter=750, momentum=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils.plot(embedding_train_2, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "embedding_test = embedding_train_2.prepare_partial(\n",
    "    x_test,\n",
    "    initialization=\"median\",\n",
    "    k=25,\n",
    "    perplexity=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "utils.plot(embedding_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "embedding_test_1 = embedding_test.optimize(\n",
    "    n_iter=100,\n",
    "    learning_rate=1,\n",
    "    exaggeration=2,\n",
    "    momentum=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot(embedding_test_1, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Together\n",
    "\n",
    "We superimpose the transformed points onto the original embedding with larger opacity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "utils.plot(embedding_train_2, y_train, alpha=0.25, ax=ax)\n",
    "utils.plot(embedding_test_1, y_test, alpha=0.75, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test inheritance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class base():\n",
    "    def __init__(self):\n",
    "        init = \"Init Base\"\n",
    "        print(init)\n",
    "    def bark(self):\n",
    "        print(\"woof\")\n",
    "        \n",
    "#currently (full override):\n",
    "class over(base):\n",
    "    def __init__(self):\n",
    "        init = \"Init Previous\"\n",
    "        print(init)\n",
    "    def berk(self):\n",
    "        print(\"dog.bark(self)\")\n",
    "\n",
    "billo = dug()  \n",
    "\n",
    "#with super:\n",
    "class sup(base):\n",
    "    def __init__(self):\n",
    "        super(deg, self).__init__()\n",
    "        init = \"Init Super\"\n",
    "        print(init)\n",
    "    def berk(self):\n",
    "        print(\"dog.bark(self)\")\n",
    "\n",
    "bello = deg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"x.shape: {}\".format(x.shape))\n",
    "arr = np.empty(x.shape)\n",
    "#print(\"arr: {}\".format(arr))\n",
    "entry = [0,1,2,3]\n",
    "arr[0] = entry\n",
    "print(\"arr + entry {}\".format(arr[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#index = neighbors, distances\n",
    "data = [[[0,1,2,3],[0,20,30,40]],[[1,1,2,3],[10,20,30,40]],[[2,1,2,3],[20,20,30,40]],\n",
    "[[3,1,2,3],[30,20,30,40]],[[4,1,2,3],[40,20,30,40]]]\n",
    "\n",
    "neighbors = np.empty((5,4))\n",
    "distances = np.empty((5,4))\n",
    "\n",
    "for i in range(len(data)):\n",
    "    #neighbors_single, distances_single = np.asarray(data[i])\n",
    "    neighbors[i], distances[i] = np.asarray(data[i])\n",
    "#    neighbors[i] = neighbors_single\n",
    "#    distances[i] = distances_single\n",
    "      \n",
    "print(neighbors)\n",
    "print(distances)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#indexarr = np.asarray(indexlist)\n",
    "#np.append(indexarr[1],np.asarray(indexlist1)[1], axis=0)\n",
    "#neig, dist = indexarr[1]\n",
    "#np.append(indexarr[0],np.asarray(indexlist1)[1], axis=0)\n",
    "\n",
    "#print(indexarr)\n",
    "\n",
    "\n",
    "#neigh = np.empty((4,4))\n",
    "#dist = np.empty\n",
    "\n",
    "#empty[0] = indexarr[0]\n",
    "#print(\"\")\n",
    "#print(empty)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test difference range, enumerate for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = [[1,2,3],[4,5,6]]\n",
    "     \n",
    "#for i,x in enumerate(X):\n",
    "#    print(i,x)\n",
    "    \n",
    "#n_items, vector_length = x.shape\n",
    "#for i, j in range(n_items):\n",
    "#    print(j[i], i)\n",
    "#print(\"\")\n",
    "#for i,j in enumerate(x):\n",
    "#    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
