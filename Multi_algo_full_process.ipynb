{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### python test class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config files\n",
    "\n",
    "Provide option to input config files, in the form I want to get, if they don't provide any, you give/use default values. \n",
    ".txt format\n",
    "\n",
    "Describe it in the documentation how it should look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openTSNE import TSNEEmbedding\n",
    "from openTSNE import initialization\n",
    "from openTSNE.callbacks import ErrorLogger\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "x, y = iris[\"data\"], iris[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set contains 150 samples with 4 features\n"
     ]
    }
   ],
   "source": [
    "print(\"Data set contains %d samples with %d features\" % x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 training samples\n",
      "50 test samples\n"
     ]
    }
   ],
   "source": [
    "print(\"%d training samples\" % x_train.shape[0])\n",
    "print(\"%d test samples\" % x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a t-SNE embedding\n",
    "\n",
    "Like in the *simple_usage* notebook, we will run the standard t-SNE optimization.\n",
    "\n",
    "This example shows the standard t-SNE optimization. Much can be done in order to better preserve global structure and improve embedding quality. Please refer to the *preserving_global_structure* notebook for some examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Compute the affinities between data points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNIndex_Elements:\n",
    "    def __init__(self, metric, metric_params=None, n_jobs=1, random_state=None):\n",
    "        self.index = None\n",
    "        self.metric = metric\n",
    "        self.metric_params = metric_params\n",
    "        self.n_jobs = n_jobs\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def build(self, data):\n",
    "        \"\"\"Build the index so we can query nearest neighbors.\"\"\"\n",
    "\n",
    "    def query_train(self, data, k):\n",
    "        \"\"\"Query the index for the points used to build index.\"\"\"\n",
    "\n",
    "    def query(self, query, k):\n",
    "        \"\"\"Query the index with new points.\"\"\"\n",
    "\n",
    "    def check_metric(self, metric):\n",
    "        \"\"\"Check that the metric is supported by the KNNIndex instance.\"\"\"\n",
    "\n",
    "class Annoy:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "class NearPy:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "class ONNG:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "class NMSLIB:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "#####       \n",
    "#self.knn_index = build_knn_index(\n",
    "#            data, method, metric, metric_params, n_jobs, random_state\n",
    "#        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import affinity_multiann.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import operator\n",
    "from functools import reduce\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "#from . import nearest_neighbors\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "from openTSNE.affinity import PerplexityBasedNN, MultiscaleMixture, FixedSigmaNN, joint_probabilities_nn\n",
    "from openTSNE import nearest_neighbors\n",
    "\n",
    "class MultiANNPerplexityBasedNN(PerplexityBasedNN):\n",
    "    \"\"\"Compute affinities using nearest neighbors.\n",
    "    \"\"\"\n",
    "\n",
    "    #super init !    \n",
    "    def __init__(\n",
    "        self,\n",
    "        data,\n",
    "        perplexity=30,\n",
    "        method=\"approx\",\n",
    "        metric=\"euclidean\",\n",
    "        metric_params=None,\n",
    "        symmetrize=True,\n",
    "        n_jobs=1,\n",
    "        random_state=None,\n",
    "    ):\n",
    "        self.n_samples = data.shape[0]\n",
    "        self.perplexity = self.check_perplexity(perplexity)\n",
    "\n",
    "        self.knn_index = build_knn_index(\n",
    "            data, method, metric, metric_params, n_jobs, random_state\n",
    "        )\n",
    "\n",
    "        # Find and store the nearest neighbors so we can reuse them if the\n",
    "        # perplexity is ever lowered\n",
    "        k_neighbors = min(self.n_samples - 1, int(3 * self.perplexity))\n",
    "        self.__neighbors, self.__distances = self.knn_index.query_train(\n",
    "            data, k=k_neighbors\n",
    "        )\n",
    "        #print(\"Neighbors:\")\n",
    "        #print(self.__neighbors)\n",
    "        #print(len(self.__neighbors))\n",
    "        #print(\"Distances:\")\n",
    "        #print(self.__distances)\n",
    "        #print(len(self.__distances[0]))\n",
    "\n",
    "        self.P = joint_probabilities_nn(\n",
    "            self.__neighbors,\n",
    "            self.__distances,\n",
    "            [self.perplexity],\n",
    "            symmetrize=symmetrize,\n",
    "            n_jobs=n_jobs,\n",
    "        )\n",
    "\n",
    "        self.n_jobs = n_jobs\n",
    "        \n",
    "        \n",
    "        \n",
    "def build_knn_index(\n",
    "    data, method, metric, metric_params=None, n_jobs=1, random_state=None\n",
    "):\n",
    "    methods = {\n",
    "        #\"exact_alt\": nearest_neighbors.VPTree,\n",
    "        \"exact\": nearest_neighbors.BallTree,\n",
    "        \"approx\": nearest_neighbors.NNDescent,\n",
    "        #cs: options for ann algorithms\n",
    "        \"balltree\": nearest_neighbors.BallTree,\n",
    "        \"nndescent\": nearest_neighbors.NNDescent,\n",
    "        #\"annoy\": multi_nearest_neighbors.Annoy, (if filelocation in sumfile)\n",
    "        #\"annoy\": algorithms.annoy.Annoy (if filelocation in folder)\n",
    "        \"annoy\": Annoy,\n",
    "        \"hnsw\": Hnsw,\n",
    "        \"sw-graph\": SWGraph,\n",
    "        \"vp-tree\": Nmslib(\"vp-tree\"),\n",
    "        \"napp\": Nmslib(\"napp\"),\n",
    "        \"simple_invindx\": Nmslib(\"simple_invindx\"),\n",
    "        \"brute_force\": BruteForce,\n",
    "        #\"hnswlib\": Hnswlib,\n",
    "        #\"rpforest\": RPForest,\n",
    "        #\"flann\": FLANN,\n",
    "        #\"onng\": ONNG,\n",
    "        \"nearpy\": NearPy,\n",
    "    }\n",
    "    if isinstance(method, nearest_neighbors.KNNIndex):\n",
    "        knn_index = method\n",
    "\n",
    "    elif method not in methods:\n",
    "        raise ValueError(\n",
    "            \"Unrecognized nearest neighbor algorithm `%s`. \"\n",
    "            \"Please choose one of the supported methods or \"\n",
    "            \"provide a valid `KNNIndex` instance.\" % method\n",
    "        )\n",
    "    else:\n",
    "        knn_index = methods[method](\n",
    "            metric=metric,\n",
    "            metric_params=metric_params,\n",
    "            n_jobs=n_jobs,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "\n",
    "    knn_index.build(data)\n",
    "\n",
    "    return knn_index        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MultiANNFixedSigmaNN(FixedSigmaNN):\n",
    "#     \"\"\"Compute affinities using using nearest neighbors and a fixed bandwidth\n",
    "#     for the Gaussians in the ambient space.\n",
    "# \n",
    "#     Using a fixed Gaussian bandwidth can enable us to find smaller clusters of\n",
    "#     data points than we might be able to using the automatically determined\n",
    "#     bandwidths using perplexity. Note however that this requires mostly trial\n",
    "#     and error.\n",
    "#     \"\"\"\n",
    "# \n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         data,\n",
    "#         sigma,\n",
    "#         k=30,\n",
    "#         method=\"exact\",\n",
    "#         metric=\"euclidean\",\n",
    "#         metric_params=None,\n",
    "#         symmetrize=True,\n",
    "#         n_jobs=1,\n",
    "#         random_state=None,\n",
    "#     ):\n",
    "#         self.n_samples = n_samples = data.shape[0]\n",
    "# \n",
    "#         if k >= self.n_samples:\n",
    "#             raise ValueError(\n",
    "#                 \"`k` (%d) cannot be larger than N-1 (%d).\" % (k, self.n_samples)\n",
    "#             )\n",
    "# \n",
    "#         knn_index, neighbors, distances = build_knn_index(\n",
    "#             data, method, k, metric, metric_params, n_jobs, random_state\n",
    "#         )\n",
    "# \n",
    "#         self.knn_index = knn_index\n",
    "# \n",
    "#         # Compute asymmetric pairwise input similarities\n",
    "#         conditional_P = np.exp(-distances ** 2 / (2 * sigma ** 2))\n",
    "#         conditional_P /= np.sum(conditional_P, axis=1)[:, np.newaxis]\n",
    "# \n",
    "#         P = sp.csr_matrix(\n",
    "#             (conditional_P.ravel(), neighbors.ravel(), range(0, n_samples * k + 1, k)),\n",
    "#             shape=(n_samples, n_samples),\n",
    "#         )\n",
    "# \n",
    "#         # Symmetrize the probability matrix\n",
    "#         if symmetrize:\n",
    "#             P = (P + P.T) / 2\n",
    "# \n",
    "#         # Convert weights to probabilities\n",
    "#         P /= np.sum(P)\n",
    "# \n",
    "#         self.sigma = sigma\n",
    "#         self.k = k\n",
    "#         self.P = P\n",
    "#         self.n_jobs = n_jobs\n",
    "#\n",
    "#\n",
    "# class MultiANNMultiscaleMixture(MultiscaleMixture):\n",
    "#     \"\"\"Calculate affinities using a Gaussian mixture kernel.\n",
    "# \n",
    "#     Instead of using a single perplexity to compute the affinities between data\n",
    "#     points, we can use a multiscale Gaussian kernel instead. This allows us to\n",
    "#     incorporate long range interactions.\n",
    "#     \"\"\"\n",
    "# \n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         data,\n",
    "#         perplexities,\n",
    "#         method=\"exact\",\n",
    "#         metric=\"euclidean\",\n",
    "#         metric_params=None,\n",
    "#         symmetrize=True,\n",
    "#         n_jobs=1,\n",
    "#         random_state=None,\n",
    "#     ):\n",
    "#         self.n_samples = data.shape[0]\n",
    "# \n",
    "#         # We will compute the nearest neighbors to the max value of perplexity,\n",
    "#         # smaller values can just use indexing to truncate unneeded neighbors\n",
    "#         perplexities = self.check_perplexities(perplexities)\n",
    "#         max_perplexity = np.max(perplexities)\n",
    "#         k_neighbors = min(self.n_samples - 1, int(3 * max_perplexity))\n",
    "# \n",
    "#         self.knn_index, self.__neighbors, self.__distances = build_knn_index(\n",
    "#             data, method, k_neighbors, metric, metric_params, n_jobs, random_state\n",
    "#         )\n",
    "# \n",
    "#         self.P = self._calculate_P(\n",
    "#             self.__neighbors,\n",
    "#             self.__distances,\n",
    "#             perplexities,\n",
    "#             symmetrize=symmetrize,\n",
    "#             n_jobs=n_jobs,\n",
    "#         )\n",
    "# \n",
    "#         self.perplexities = perplexities\n",
    "#         self.n_jobs = n_jobs\n",
    "# \n",
    "# class MultiANNMultiscale(MultiANNMultiscaleMixture):\n",
    "#     \"\"\"Calculate affinities using averaged Gaussian perplexities.\n",
    "# \n",
    "#     In contrast to :class:`MultiscaleMixture`, which uses a Gaussian mixture\n",
    "#     kernel, here, we first compute single scale Gaussian kernels, convert them\n",
    "#     to probability distributions, then average them out between scales.\n",
    "# \n",
    "#     Please see the :ref:`parameter-guide` for more information.\n",
    "#     \"\"\"\n",
    "# \n",
    "#     @staticmethod\n",
    "#     def _calculate_P(\n",
    "#         neighbors,\n",
    "#         distances,\n",
    "#         perplexities,\n",
    "#         symmetrize=True,\n",
    "#         normalization=\"pair-wise\",\n",
    "#         n_reference_samples=None,\n",
    "#         n_jobs=1,\n",
    "#     ):\n",
    "#         # Compute normalized probabilities for each perplexity\n",
    "#         partial_Ps = [\n",
    "#             joint_probabilities_nn(\n",
    "#                 neighbors,\n",
    "#                 distances,\n",
    "#                 [perplexity],\n",
    "#                 symmetrize=symmetrize,\n",
    "#                 normalization=normalization,\n",
    "#                 n_reference_samples=n_reference_samples,\n",
    "#                 n_jobs=n_jobs,\n",
    "#             )\n",
    "#             for perplexity in perplexities\n",
    "#         ]\n",
    "#         # Sum them together, then normalize\n",
    "#         P = reduce(operator.add, partial_Ps, 0)\n",
    "# \n",
    "#         # Take care to properly normalize the affinity matrix\n",
    "#         if normalization == \"pair-wise\":\n",
    "#             P /= np.sum(P)\n",
    "#         elif normalization == \"point-wise\":\n",
    "#             P = sp.diags(np.asarray(1 / P.sum(axis=1)).ravel()) @ P\n",
    "# \n",
    "#         return P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import multi_nearest_neighbors.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### annparameters.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_method_param(method, data=None):\n",
    "    \"\"\"\n",
    "    Get method parameters based on approximate nearest neighbor algorithm and data (shape, vector)\n",
    "    \n",
    "    Input: name of method as string, data as np.array ([num_items][vector_length])\n",
    "    Output: method_param as directory. Keys corresponding to the method-specific parameters\n",
    "    \"\"\"\n",
    "    config_file = \"\"\n",
    "    config_file = None\n",
    "\n",
    "    if method == \"nearpy\":\n",
    "        if not config_file:\n",
    "            mp = {}\n",
    "            \n",
    "            # number of bits, as int\n",
    "            mp['n_bits'] = 20 # ????? How many as standard? \n",
    "            \n",
    "            # hash counts, as int\n",
    "            mp['hash_counts'] = 20 # ????? How many as standard? \n",
    "    \n",
    "    elif method == \"annoy\":\n",
    "\n",
    "        if not config_file:\n",
    "            n_items, vector_length = data.shape\n",
    "            mp = {}\n",
    "            \n",
    "            # number of trees, as int\n",
    "            mp[\"ntrees\"] = 5 + int(round((n_items) ** 0.5 / 20))\n",
    "            \n",
    "    elif method == \"onng\":\n",
    "        \"\"\"\n",
    "        https://github.com/yahoojapan/NGT/blob/master/python/README-ngtpy.md\n",
    "        \n",
    "        object_type: Specifies the data object type.\n",
    "            c: 1 byte unsigned integer\n",
    "            f: 4 byte floating point number (default)\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        if not config_file:\n",
    "            mp = {}\n",
    "            mp[\"object_type\"] = \"f\"\n",
    "            \n",
    "            mp[\"edge_size_for_search\"] = -2\n",
    "            \n",
    "            mp[\"build_time_limit\"] = 4\n",
    "            \n",
    "            mp[\"epsilon\"] = 10\n",
    "            \n",
    "            mp[\"edge\"] = 100\n",
    "            \n",
    "            mp[\"outdegree\"] = 10\n",
    "            \n",
    "            mp[\"indegree\"] = 120\n",
    "    \n",
    "    elif method == \"hnsw\": \n",
    "    \n",
    "        if not config_file:\n",
    "            mp = {}\n",
    "            \n",
    "            M = 15\n",
    "            efC = 100\n",
    "            mp[\"index_param\"] = {'M': M, 'efConstruction': efC, 'post' : 0}\n",
    "            efS = 100\n",
    "            mp['query_param'] = {'efSearch': efS}\n",
    "            \n",
    "    elif method == \"sw-graph\": \n",
    "        \n",
    "        if not config_file:\n",
    "            mp = {}\n",
    "            \n",
    "            M = 15\n",
    "            efC = 100\n",
    "            mp[\"index_param\"] = {'M': M, 'efConstruction': efC, 'post' : 0}\n",
    "            efS = 100\n",
    "            mp['query_param'] = {'efSearch': efS}\n",
    "            \n",
    "    elif method == \"vp-tree\": \n",
    "        \n",
    "        if not config_file:\n",
    "            n_items, dim = data.shape\n",
    "            mp = {}\n",
    "            \n",
    "            M = 15\n",
    "            efC = 100\n",
    "            bS = min(int(dim * 0.0005), 1000)\n",
    "            mp[\"index_param\"] = {'M': M, 'efConstruction': efC, 'bucketSize': bS,'post' : 0}\n",
    "            mp['query_param'] = None\n",
    "            \n",
    "    elif method == \"napp\": \n",
    "        \n",
    "        if not config_file:\n",
    "            mp = {}\n",
    "            \n",
    "            M = 15\n",
    "            efC = 100\n",
    "            mp[\"index_param\"] = {'M': M, 'efConstruction': efC, 'post' : 0}\n",
    "            mp['query_param'] = None\n",
    "            \n",
    "    elif method == \"simple_invindx\": \n",
    "        \n",
    "        if not config_file:\n",
    "            mp = {}\n",
    "            \n",
    "            M = 15\n",
    "            efC = 100\n",
    "            mp[\"index_param\"] = {'M': M, 'efConstruction': efC, 'post' : 0}\n",
    "            mp['query_param'] = None\n",
    "            \n",
    "    else:\n",
    "        print(\"Error: ANN for init_method_param not found\")\n",
    "        return \n",
    "        \n",
    "    return mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index_param': {'M': 15, 'efConstruction': 100, 'post': 0}, 'query_param': {'efSearch': 1000}}\n"
     ]
    }
   ],
   "source": [
    "print(init_method_param(\"sw-graph\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMSLIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openTSNE.nearest_neighbors import KNNIndex\n",
    "\n",
    "import nmslib\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class Nmslib(KNNIndex):\n",
    "    #def __init__(self, method):\n",
    "    #    super(Nmslib, self).__init__()\n",
    "    #    self._method_name = method\n",
    "    \n",
    "    #VALID_METRICS = neighbors.Nmslib.valid_metrics\n",
    "    __\n",
    "    \n",
    "    def build(self, data):\n",
    "        n_items, vector_length = data.shape\n",
    "        #self._method_name = \"hnsw\"\n",
    "        #initalize parameters\n",
    "        method_param = init_method_param(self._method_name, data)\n",
    "        \n",
    "        \n",
    "        #self._save_index = method_param[\"save_index\"]\n",
    "        self._index_param = method_param[\"index_param\"]\n",
    "        self._index_param[\"indexThreadQty\"] = self.n_jobs \n",
    "        self._query_param = method_param[\"query_param\"]\n",
    "        #self._name = mp['name']\n",
    "        ef = mp['efS']\n",
    "        self._metric = {\n",
    "        'angular': 'cosinesimil', 'euclidean': 'l2'}[self.metric]\n",
    "        \n",
    "        #create dir\n",
    "        #self._index_name = os.path.join(INDEX_DIR, \"nmslib_%s_%s_%s\" % (\n",
    "        #    self._method_name, self.metric, '_'.join(self._index_param)))\n",
    "\n",
    "        #d = os.path.dirname(self._index_name)\n",
    "        #if not os.path.exists(d):\n",
    "        #    os.makedirs(d)\n",
    "\n",
    "        #fit\n",
    "        if self._method_name == 'vptree':\n",
    "            # To avoid this issue: terminate called after throwing an instance\n",
    "            # of 'std::runtime_error'\n",
    "            # what():  The data size is too small or the bucket size is too\n",
    "            # big. Select the parameters so that <total # of records> is NOT\n",
    "            # less than <bucket size> * 1000\n",
    "            # Aborted (core dumped)\n",
    "            self._index_param.append('bucketSize=%d' %\n",
    "                                     min(int(data.shape[0] * 0.0005), 1000))\n",
    "\n",
    "        self.index = nmslib.init(\n",
    "            space=self._metric, method=self._method_name, data_type=nmslib.DataType.DENSE_VECTOR, dtype=nmslib.DistType.FLOAT)\n",
    "        self.index.addDataPointBatch(data)\n",
    "\n",
    "        #if os.path.exists(self._index_name):\n",
    "        #    print('Loading index from file')\n",
    "        #    self._index.loadIndex(self._index_name)\n",
    "        #else:\n",
    "        self.index.createIndex(self._index_param)\n",
    "        #    if self._save_index:\n",
    "        #        self.index.saveIndex(self._index_name)\n",
    "        if self._query_param is not None:\n",
    "            self.index.setQueryTimeParams(self._query_param)\n",
    "    \n",
    "        #set query arguments\n",
    "        if self._method_name == 'hnsw' or self._method_name == 'sw-graph':\n",
    "            self.index.setQueryTimeParams([\"efSearch=%s\" % (ef)])\n",
    "\n",
    "    def query_train(self, data, k):\n",
    "        result = np.asarray(self.index.knnQueryBatch(data, k))\n",
    "        #for i in \n",
    "        #print(self.res)\n",
    "        #return self.res\n",
    "        neighbors = np.empty((data.shape[0],k), dtype=int)\n",
    "        distances = np.empty((data.shape[0],k))\n",
    "        for i in range(len(data)):\n",
    "            neighbors[i] = result[i][0] \n",
    "            distances[i] = result[i][1]\n",
    "        return neighbors, distances\n",
    "    \n",
    "    def query(self, query, k):\n",
    "        result = np.asarray(self.index.knnQueryBatch(query, k))\n",
    "        #for i in \n",
    "        #print(self.res)\n",
    "        #return self.res\n",
    "        neighbors = np.empty((query.shape[0],k), dtype=int)\n",
    "        distances = np.empty((query.shape[0],k))\n",
    "        for i in range(len(query)):\n",
    "            neighbors[i] = result[i][0] \n",
    "            distances[i] = result[i][1]\n",
    "        return neighbors, distances\n",
    "\n",
    "class Hnsw(Nmslib):\n",
    "    def __init__(self):\n",
    "        super(Hnsw, self).__init__()\n",
    "        self._method_name = \"hnsw\"\n",
    "        \n",
    "class SWGraph(Nmslib):\n",
    "    def __init__(self, metric, metric_params=None, n_jobs=1, random_state=None):\n",
    "        super(SWGraph,self).__init__(metric, metric_params, n_jobs, random_state)\n",
    "        self.index = None\n",
    "        self.metric = metric\n",
    "        self.metric_params = metric_params\n",
    "        self.n_jobs = n_jobs\n",
    "        self.random_state = random_state\n",
    "        self._method_name = \"sw-graph\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openTSNE.nearest_neighbors import KNNIndex\n",
    "\n",
    "import nmslib\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class SWGraph(KNNIndex):\n",
    "    #VALID_METRICS = neighbors.Nmslib.valid_metrics\n",
    "    \n",
    "    def build(self, data):\n",
    "        n_items, vector_length = data.shape\n",
    "        self._method_name = \"sw-graph\"\n",
    "        method_param = init_method_param(self._method_name, data)\n",
    "        self._index_param = method_param[\"index_param\"]\n",
    "        self._index_param[\"indexThreadQty\"] = self.n_jobs \n",
    "        self._query_param = method_param[\"query_param\"]\n",
    "        self._metric = {\n",
    "        'angular': 'cosinesimil', 'euclidean': 'l2'}[self.metric]\n",
    "\n",
    "        self.index = nmslib.init(\n",
    "            space=self._metric, method=self._method_name, data_type=nmslib.DataType.DENSE_VECTOR, dtype=nmslib.DistType.FLOAT)\n",
    "        self.index.addDataPointBatch(data)\n",
    "        self.index.createIndex(self._index_param)\n",
    "        self.index.setQueryTimeParams(self._query_param)\n",
    "\n",
    "    def query_train(self, data, k):\n",
    "        result = np.asarray(self.index.knnQueryBatch(data, k))\n",
    "        neighbors = np.empty((data.shape[0],k), dtype=int)\n",
    "        distances = np.empty((data.shape[0],k))\n",
    "        for i in range(len(data)):\n",
    "            neighbors[i] = result[i][0] \n",
    "            distances[i] = result[i][1]\n",
    "        return neighbors, distances\n",
    "    \n",
    "    def query(self, query, k):\n",
    "        result = np.asarray(self.index.knnQueryBatch(query, k))\n",
    "        neighbors = np.empty((query.shape[0],k), dtype=int)\n",
    "        distances = np.empty((query.shape[0],k))\n",
    "        for i in range(len(query)):\n",
    "            neighbors[i] = result[i][0] \n",
    "            distances[i] = result[i][1]\n",
    "        return neighbors, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openTSNE.nearest_neighbors import KNNIndex\n",
    "\n",
    "import nmslib\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class Hnsw(KNNIndex):\n",
    "    #VALID_METRICS = neighbors.Nmslib.valid_metrics\n",
    "    \n",
    "    def build(self, data):\n",
    "        n_items, vector_length = data.shape\n",
    "        self._method_name = \"hnsw\"\n",
    "        method_param = init_method_param(self._method_name, data)\n",
    "        self._index_param = method_param[\"index_param\"]\n",
    "        self._index_param[\"indexThreadQty\"] = self.n_jobs \n",
    "        self._query_param = method_param[\"query_param\"]\n",
    "        self._metric = {\n",
    "        'angular': 'cosinesimil', 'euclidean': 'l2'}[self.metric]\n",
    "\n",
    "        self.index = nmslib.init(\n",
    "            space=self._metric, method=self._method_name, data_type=nmslib.DataType.DENSE_VECTOR, dtype=nmslib.DistType.FLOAT)\n",
    "        self.index.addDataPointBatch(data)\n",
    "        self.index.createIndex(self._index_param)\n",
    "        self.index.setQueryTimeParams(self._query_param)\n",
    "\n",
    "    def query_train(self, data, k):\n",
    "        result = np.asarray(self.index.knnQueryBatch(data, k))\n",
    "        neighbors = np.empty((data.shape[0],k), dtype=int)\n",
    "        distances = np.empty((data.shape[0],k))\n",
    "        for i in range(len(data)):\n",
    "            neighbors[i] = result[i][0] \n",
    "            distances[i] = result[i][1]\n",
    "        return neighbors, distances\n",
    "    \n",
    "    def query(self, query, k):\n",
    "        result = np.asarray(self.index.knnQueryBatch(query, k))\n",
    "        neighbors = np.empty((query.shape[0],k), dtype=int)\n",
    "        distances = np.empty((query.shape[0],k))\n",
    "        for i in range(len(query)):\n",
    "            neighbors[i] = result[i][0] \n",
    "            distances[i] = result[i][1]\n",
    "        return neighbors, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openTSNE.nearest_neighbors import KNNIndex\n",
    "\n",
    "import nmslib\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class BruteForce(KNNIndex):\n",
    "    #VALID_METRICS = neighbors.Nmslib.valid_metrics\n",
    "    \n",
    "    def build(self, data):\n",
    "        n_items, vector_length = data.shape\n",
    "        self._method_name = \"brute_force\"\n",
    "        self._metric = {\n",
    "        'angular': 'cosinesimil', 'euclidean': 'l2'}[self.metric]\n",
    "\n",
    "        self.index = nmslib.init(\n",
    "            space=self._metric, method=self._method_name, data_type=nmslib.DataType.DENSE_VECTOR, dtype=nmslib.DistType.FLOAT)\n",
    "       \n",
    "        self.index.addDataPointBatch(data)\n",
    "        self.index.createIndex()\n",
    "\n",
    "    def query_train(self, data, k):\n",
    "        result = np.asarray(self.index.knnQueryBatch(data, k))\n",
    "        neighbors = np.empty((data.shape[0],k), dtype=int)\n",
    "        distances = np.empty((data.shape[0],k))\n",
    "        for i in range(len(data)):\n",
    "            neighbors[i] = result[i][0] \n",
    "            distances[i] = result[i][1]\n",
    "        return neighbors, distances\n",
    "    \n",
    "    def query(self, query, k):\n",
    "        result = np.asarray(self.index.knnQueryBatch(query, k))\n",
    "        neighbors = np.empty((query.shape[0],k), dtype=int)\n",
    "        distances = np.empty((query.shape[0],k))\n",
    "        for i in range(len(query)):\n",
    "            neighbors[i] = result[i][0] \n",
    "            distances[i] = result[i][1]\n",
    "        return neighbors, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:\n",
      "  (0, 58)\t1.1123856191126478e-48\n",
      "  (0, 63)\t1.629381818051472e-47\n",
      "  (0, 73)\t1.5443295993298925e-46\n",
      "  (0, 65)\t7.618908252567122e-46\n",
      "  (0, 87)\t1.2659956581135655e-45\n",
      "  (0, 51)\t1.361279451433849e-45\n",
      "  (0, 75)\t3.7587606280968164e-45\n",
      "  (0, 91)\t4.041633163961909e-45\n",
      "  (0, 106)\t5.024286834345004e-45\n",
      "  (0, 78)\t1.1373116778461108e-43\n",
      "  (0, 85)\t2.0320429640373955e-43\n",
      "  (0, 66)\t1.4684333760073635e-41\n",
      "  (0, 74)\t3.770849500982889e-41\n",
      "  (0, 55)\t3.7708940636562237e-41\n",
      "  (0, 84)\t4.687778032095442e-41\n",
      "  (0, 97)\t1.2268324422718476e-39\n",
      "  (0, 90)\t6.052593783026402e-39\n",
      "  (0, 61)\t3.2721531985417874e-37\n",
      "  (0, 94)\t1.0645757646313081e-35\n",
      "  (0, 62)\t1.4229865461859848e-35\n",
      "  (0, 96)\t3.654254097655959e-35\n",
      "  (0, 53)\t1.55931299641511e-34\n",
      "  (0, 71)\t3.463470407810223e-34\n",
      "  (0, 95)\t3.724106684873443e-34\n",
      "  (0, 99)\t7.692885885901127e-34\n",
      "  :\t:\n",
      "  (149, 66)\t7.330877936349828e-05\n",
      "  (149, 116)\t7.599730076727377e-05\n",
      "  (149, 78)\t7.03352077202577e-05\n",
      "  (149, 56)\t0.00010558619198568894\n",
      "  (149, 91)\t8.089484542949024e-05\n",
      "  (149, 110)\t0.00010514943370423587\n",
      "  (149, 146)\t0.00012319205315800593\n",
      "  (149, 137)\t0.00012026321604423454\n",
      "  (149, 103)\t0.00013056033586095764\n",
      "  (149, 114)\t0.00021544346852801004\n",
      "  (149, 147)\t0.0001061385506654824\n",
      "  (149, 111)\t0.00012617327534216203\n",
      "  (149, 63)\t0.00011659041473327155\n",
      "  (149, 113)\t0.0002226519553219883\n",
      "  (149, 133)\t0.00019368156378631995\n",
      "  (149, 123)\t0.00018253938249201694\n",
      "  (149, 126)\t0.0002449212382791976\n",
      "  (149, 121)\t0.0003351397451320423\n",
      "  (149, 83)\t0.0003792148904964361\n",
      "  (149, 70)\t0.0004211395245416383\n",
      "  (149, 142)\t0.0004301334718734168\n",
      "  (149, 101)\t0.0004301334718734168\n",
      "  (149, 138)\t0.0004307341317329757\n",
      "  (149, 127)\t0.00046861379804921465\n",
      "  (149, 149)\t0.00069446280453884\n",
      "\n",
      "knn_index:\n",
      "<__main__.BruteForce object at 0x11ccdcd30>\n"
     ]
    }
   ],
   "source": [
    "affinities_train = MultiANNPerplexityBasedNN(\n",
    "    x,\n",
    "    perplexity=30,\n",
    "    method=\"brute_force\",\n",
    "    metric=\"euclidean\",\n",
    "    n_jobs=8,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "#possible solution\n",
    "#affinities_train.knn_index = stelmach.build_knn_index()\n",
    "\n",
    "print(\"P:\")\n",
    "print(affinities_train.P)\n",
    "print(\"\")\n",
    "\n",
    "#print(\"data:\")\n",
    "#print(affinities_train.data)\n",
    "#print(\"\")\n",
    "\n",
    "print(\"knn_index:\")\n",
    "print(affinities_train.knn_index)\n",
    "\n",
    "#print(\".index\")\n",
    "#print(affinities_train.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONNG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ngtpy.cpython-37m-darwin.so, 2): Library not loaded: /usr/local/opt/gcc/lib/gcc/8/libgomp.1.dylib\n  Referenced from: /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ngtpy.cpython-37m-darwin.so\n  Reason: image not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-6d1e2d2d4ad1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#from __future__ import absolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mngtpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ngtpy.cpython-37m-darwin.so, 2): Library not loaded: /usr/local/opt/gcc/lib/gcc/8/libgomp.1.dylib\n  Referenced from: /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ngtpy.cpython-37m-darwin.so\n  Reason: image not found"
     ]
    }
   ],
   "source": [
    "#from __future__ import absolute_import\n",
    "import ngtpy\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "class ONNG(KNNIndex):\n",
    "    #VALID_METRICS = neighbors.ONNG.valid_metrics\n",
    "    \n",
    "    def build(self, data):\n",
    "        #metrics = {'euclidean': '2', 'angular': 'C'}\n",
    "        method_param = init_method_param(\"onng\")\n",
    "        n_items, dim = data.shape \n",
    "        self._edge_size = method_param[\"edge\"]\n",
    "        self._outdegree = method_param[\"outdegree\"]\n",
    "        self._indegree = method_param[\"indegree\"]\n",
    "        self._object_type = method_param[\"object_type\"]\n",
    "        self._edge_size_for_search = method_param[\"edge_size_for_search\"]\n",
    "        self._build_time_limit = method_param[\"build_time_limit\"]\n",
    "        self._epsilon = method_param[\"epsilon\"]\n",
    "            \n",
    "            \n",
    "            \n",
    "        print('ONNG: start indexing...')\n",
    "        print('ONNG: # of data=' + str(len(data)))\n",
    "        print('ONNG: dimensionality=' + str(dim))\n",
    "        index_dir = 'indexes'\n",
    "        if not os.path.exists(index_dir):\n",
    "            os.makedirs(index_dir)\n",
    "        index = os.path.join(\n",
    "            index_dir,\n",
    "            'ONNG-{}-{}-{}'.format(self._edge_size, self._outdegree,\n",
    "                                   self._indegree))\n",
    "        anngIndex = os.path.join(index_dir, 'ANNG-' + str(self._edge_size))\n",
    "        print('ONNG: index=' + index)\n",
    "        if (not os.path.exists(index)) and (not os.path.exists(anngIndex)):\n",
    "            print('ONNG: create ANNG')\n",
    "            t = time.time()\n",
    "            args = ['ngt', 'create', '-it', '-p8', '-b500', '-ga', '-of',\n",
    "                    '-D' + self.metric, '-d' + str(dim),\n",
    "                    '-E' + str(self._edge_size), '-S0',\n",
    "                    '-e' + str(self._epsilon), '-P0', '-B30',\n",
    "                    '-T' + str(self._build_time_limit), anngIndex]\n",
    "            subprocess.call(args)\n",
    "            idx = ngt.Index(path=anngIndex)\n",
    "            idx.batch_insert(data, num_threads=24, debug=False)\n",
    "            idx.save()\n",
    "            idx.close()\n",
    "            print('ONNG: ANNG construction time(sec)=' + str(time.time() - t))\n",
    "        if not os.path.exists(index):\n",
    "            print('ONNG: degree adjustment')\n",
    "            t = time.time()\n",
    "            args = ['ngt', 'reconstruct-graph', '-mS',\n",
    "                    '-o ' + str(self._outdegree),\n",
    "                    '-i ' + str(self._indegree), anngIndex, index]\n",
    "            subprocess.call(args)\n",
    "            print('ONNG: degree adjustment time(sec)=' + str(time.time() - t))\n",
    "        if os.path.exists(index):\n",
    "            print('ONNG: index already exists! ' + str(index))\n",
    "            t = time.time()\n",
    "            self.index = ngt.Index(index, read_only=True)\n",
    "            self.indexName = index\n",
    "            print('ONNG: open time(sec)=' + str(time.time() - t))\n",
    "        else:\n",
    "            print('ONNG: something wrong.')\n",
    "        print('ONNG: end of fit')\n",
    "        \n",
    "    \n",
    "    def query_train(self, data, k):\n",
    "        results = self.index.search(\n",
    "            data, k, self._epsilon, self._edge_size_for_search,\n",
    "            with_distance=False)\n",
    "        return results\n",
    "    \n",
    "    \"\"\"\n",
    "    def query_train(self, data, k):    \n",
    "        neighbors, distances = self.index.search(\n",
    "            v, k, self._epsilon, self._edge_size_for_search,\n",
    "            with_distance=False)\n",
    "        return neighbors, distances\n",
    "        \n",
    "        \n",
    "    def query(self, query, k):\n",
    "        #check in what format results are, get neighbors, distances\n",
    "        neighbors, distances = self.index.search(\n",
    "            v, k, self._epsilon, self._edge_size_for_search,\n",
    "            with_distance=False)\n",
    "        return neighbors, distances\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FLANN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyflann'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-104417a4c19e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyflann\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mFLANN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKNNIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#VALID_METRICS = neighbors.Flann.valid_metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyflann'"
     ]
    }
   ],
   "source": [
    "import pyflann\n",
    "\n",
    "class FLANN(KNNIndex):\n",
    "    #VALID_METRICS = neighbors.Flann.valid_metrics\n",
    "    \n",
    "    def build(self, data):\n",
    "        #parameters init\n",
    "        if self.method_param == None:\n",
    "            self.method_param = {}\n",
    "            self.method_param['target_precision'] = 0.9  # want 90% target precision  \n",
    "        self._metric = metric\n",
    "        \n",
    "        self.index = pyflann.FLANN(\n",
    "            target_precision=self._target_precision,\n",
    "            algorithm='autotuned', \n",
    "            log_level='info')\n",
    "        if self._metric == 'angular':\n",
    "            data = sklearn.preprocessing.normalize(data, axis=1, norm='l2')\n",
    "        self.index.build_index(data)\n",
    "\n",
    "\n",
    "###### \n",
    "    def query_train(self, data, k):\n",
    "        if self._metric == 'angular':\n",
    "            v = sklearn.preprocessing.normalize([v], axis=1, norm='l2')[0]\n",
    "        if v.dtype != numpy.float32:\n",
    "            v = v.astype(numpy.float32)\n",
    "        return self._flann.nn_index(v, n)[0][0]\n",
    "\n",
    "    def query(self, query, k):\n",
    "        if self._metric == 'angular':\n",
    "            v = sklearn.preprocessing.normalize([v], axis=1, norm='l2')[0]\n",
    "        if v.dtype != numpy.float32:\n",
    "            v = v.astype(numpy.float32)\n",
    "        return self._flann.nn_index(v, n)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RPForest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpforest\n",
    "import numpy\n",
    "\n",
    "\n",
    "class RPForest(KNNIndex):\n",
    "    #VALID_METRICS = neighbors.Annoy.valid_metrics\n",
    "    \n",
    "    def build(self, data):\n",
    "        n_trees = 5 + int(round((data.shape[0]) ** 0.5 / 20))\n",
    "        #n_iters = max(5, int(round(np.log2(data.shape[0]))))\n",
    "        leaf_size = ?\n",
    "        \n",
    "        self.index = rpforest.RPForest(leaf_size=leaf_size, no_trees=n_trees)\n",
    "        \n",
    "        #if data.dtype != numpy.double:\n",
    "        #    data = numpy.array(data).astype(numpy.double)\n",
    "        self.index.fit(data)\n",
    "\n",
    "    def query_train(self, data, k):\n",
    "        neighbors, distances = self._model.query(data[0], k)\n",
    "        return neighbors, distances\n",
    "\n",
    "    def query(self, query, k):\n",
    "        neighbors, distances = self._model.query(data[0], k)\n",
    "        return neighbors, distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hnswlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "import hnswlib\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class HnswLib(KNNIndex):\n",
    "    #VALID_METRICS = neighbors.Annoy.valid_metrics\n",
    "    \n",
    "    def build(self,data):  \n",
    "        #parameter init\n",
    "        #self.metric = {'angular': 'cosine', 'euclidean': 'l2'}[metric]\n",
    "        if self.method_param == None:\n",
    "            self.method_param = {}\n",
    "            self.method_param[\"efConstruction\"] = 200\n",
    "            self.method_param[\"M\"] = 16\n",
    "            self.method_param[\"efRecall\"] = 10\n",
    "            #self.name = 'hnswlib (%s)' % (self.method_param)\n",
    "        \n",
    "        \n",
    "        self.index = hnswlib.Index(space=self.metric, dim=len(data[0]))\n",
    "        self.index.init_index(max_elements=len(data),\n",
    "                          ef_construction=self.method_param[\"efConstruction\"],\n",
    "                          M=self.method_param[\"M\"])\n",
    "        data_labels = np.arange(len(data))\n",
    "        self.index.add_items(np.asarray(data), data_labels)\n",
    "        self.index.set_num_threads(self.n_jobs)\n",
    "        self.index.set_ef(self.method_param[\"efRecall\"])\n",
    "\n",
    "    def query(self, query, k):\n",
    "        neighbors, distances = self.index.knn_query(query, k=k)\n",
    "        return neighbors, distances\n",
    "    \n",
    "    def query_train(self, data, k):\n",
    "        neighbors, distances = self.index.knn_query(data, k=k)\n",
    "        return neighbors, distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NearPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openTSNE.nearest_neighbors import KNNIndex\n",
    "import nearpy\n",
    "from nearpy.filters import NearestFilter\n",
    "import sklearn.preprocessing\n",
    "\n",
    "class NearPy(KNNIndex):\n",
    "    #VALID_METRICS = neighbors.NearPy.valid_metrics\n",
    "    #METHOD_PARAMS = neighbors.NearPy.params (text/config file)\n",
    "    \n",
    "    def build(self, data): \n",
    "        n_items, vector_length = data.shape\n",
    "        print(data.shape)\n",
    "        #parameters init\n",
    "        method_param = init_method_param(\"nearpy\")\n",
    "        hash_counts = method_param[\"hash_counts\"]\n",
    "        n_bits = method_param[\"n_bits\"]\n",
    "        \n",
    "        self.filter = NearestFilter(10)\n",
    "        \n",
    "        hashes = []\n",
    "        for k in range(hash_counts):\n",
    "            nearpy_rbp = nearpy.hashes.RandomBinaryProjections(\n",
    "                'rbp_%d' % k, n_bits)\n",
    "            hashes.append(nearpy_rbp)\n",
    "\n",
    "        if self.metric == 'euclidean':\n",
    "            dist = nearpy.distances.EuclideanDistance()\n",
    "            self.index = nearpy.Engine(\n",
    "                vector_length,\n",
    "                lshashes=hashes,\n",
    "                distance=dist,\n",
    "                vector_filters=[self.filter])\n",
    "        else:  # Default (angular) = Cosine distance\n",
    "            self.index = nearpy.Engine(\n",
    "                vector_length,\n",
    "                lshashes=hashes,\n",
    "                vector_filters=[self.filter])\n",
    "            \n",
    "        #if self.metric == 'angular':\n",
    "            #data = sklearn.preprocessing.normalize(data, axis=1, norm='l2')\n",
    "        for i, x in enumerate(data):\n",
    "            self.index.store_vector(x, i)\n",
    "            \n",
    "    def query_train(self, data, k):\n",
    "        self.filter.N = k\n",
    "        #if self.metric == 'angular':\n",
    "            #data = sklearn.preprocessing.normalize([data], axis=1, norm='l2')[0]\n",
    "        \n",
    "        neighbors = np.empty((data.shape[0],k), dtype=int)\n",
    "        distances = np.empty((data.shape[0],k))\n",
    "        \n",
    "        for i in range(len(data)):\n",
    "            item_single = self.index.neighbours(data[i])\n",
    "            dp_n = []\n",
    "            dp_d = []\n",
    "            for j in range(len(item_single)):\n",
    "                dp_n.append(item_single[j][1])\n",
    "                dp_d.append(item_single[j][2])\n",
    "            neighbors[i] = np.asarray(dp_n)\n",
    "            distances[i] = np.asarray(dp_d)\n",
    "            \n",
    "        return neighbors, distances\n",
    "\n",
    "    def query(self, query, k):\n",
    "        self.filter.N = k\n",
    "        #if self.metric == 'angular':\n",
    "        #    query = sklearn.preprocessing.normalize([query], axis=1, norm='l2')[0]\n",
    "        neighbors = np.empty((query.shape[0],k), dtype=int)\n",
    "        distances = np.empty((query.shape[0],k))\n",
    "        \n",
    "        for i in range(len(query)):\n",
    "            item_single = self.index.neighbours(data[i])\n",
    "            dp_n = []\n",
    "            dp_d = []\n",
    "            for j in range(len(item_single)):\n",
    "                dp_n.append(item_single[j][1])\n",
    "                dp_d.append(item_single[j][2])\n",
    "            neighbors[i] = np.asarray(dp_n)\n",
    "            distances[i] = np.asarray(dp_d)\n",
    "            \n",
    "        return neighbors, distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annoy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openTSNE.nearest_neighbors import KNNIndex\n",
    "import annoy\n",
    "import numpy as np\n",
    "\n",
    "class Annoy(KNNIndex):\n",
    "    #VALID_METRICS = neighbors.Annoy.valid_metrics\n",
    "    \n",
    "    def build(self, data):\n",
    "        n_items, vector_length = data.shape\n",
    "        #initalize parameters\n",
    "        method_param = init_method_param(\"annoy\", data)\n",
    "        ntrees = method_param[\"ntrees\"]\n",
    "        #build index\n",
    "        self.index = annoy.AnnoyIndex(vector_length, metric=self.metric)\n",
    "        for i in range(n_items):\n",
    "            self.index.add_item(i, data[i])\n",
    "        self.index.build(ntrees)\n",
    "        \n",
    "    def query_train(self, data, k):\n",
    "        #add search_k parameter: tradeoff between speed and accuracy?\n",
    "        #neighbors_single, distances_single = np.asarray(self.index.get_nns_by_vector(data[i], n=k, search_k=-1, include_distances=True))\n",
    "        #output array with points x neighbors:\n",
    "        neighbors = np.empty((data.shape[0],k), dtype=int)\n",
    "        distances = np.empty((data.shape[0],k))\n",
    "        for i in range(len(data)):\n",
    "            neighbors_single, distances_single = np.asarray(self.index.get_nns_by_item(i, n=k, search_k=-1 ,include_distances=True))\n",
    "            neighbors[i] = neighbors_single\n",
    "            distances[i] = distances_single\n",
    "        print(\"neighbors.shape: {}\".format(neighbors.shape))\n",
    "        print(\"neighbors[0]: {}\".format(neighbors[0]))\n",
    "        print(neighbors.shape)\n",
    "        print(\"distances.shape: {}\".format(distances.shape))\n",
    "        print(\"distances[0]: {}\".format(distances[0]))\n",
    "        return neighbors, distances\n",
    "\n",
    "    def query(self, query, k):\n",
    "        neighbors = np.empty((query.shape[0],k), dtype=int)\n",
    "        distances = np.empty((query.shape[0],k))\n",
    "        for i in range(len(query)):\n",
    "            neighbors_single, distances_single = np.asarray(self.index.get_nns_by_vector(query[i], n=k, search_k=-1, include_distances=True))\n",
    "            neighbors[i] = neighbors_single\n",
    "            distances[i] = distances_single\n",
    "        return neighbors, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors.shape: (150, 90)\n",
      "neighbors[0]: [  0  17   4  28  27  39   7  40  49  37  21  48  26  19  46  11  35  10\n",
      "  31  36  20  34  43   9  23   2   6  30   1  29  25  16  47  12  24  45\n",
      "  44   5  32  22   3  18  42  33  38  14   8  13  15  41  98  57  93  79\n",
      "  64  81  60  80  69  59  82  88  67  92  89  99  95  71  53  96  62  94\n",
      "  61  90  97  84  55  74  66  85  78 106  91  75  51  87  65  73  63  58]\n",
      "(150, 90)\n",
      "distances.shape: (150, 90)\n",
      "distances[0]: [0.         0.10000001 0.14142123 0.14142123 0.1414213  0.1414213\n",
      " 0.17320499 0.17320505 0.2236068  0.24494879 0.30000004 0.30000022\n",
      " 0.31622773 0.33166245 0.36055511 0.37416551 0.37416565 0.37416592\n",
      " 0.38729846 0.41231066 0.43589005 0.45825756 0.45825759 0.46904159\n",
      " 0.46904165 0.509902   0.51961523 0.5385164  0.5385164  0.53851658\n",
      " 0.54772258 0.5477227  0.58309519 0.59160781 0.59160781 0.59160781\n",
      " 0.61644137 0.61644155 0.62449968 0.64807403 0.64807415 0.74161977\n",
      " 0.76811439 0.80622566 0.86602527 0.88317627 0.92195427 0.99498719\n",
      " 1.10453606 1.34907377 2.09045458 2.34520769 2.38746715 2.49399257\n",
      " 2.5806973  2.70185137 2.70370102 2.81780052 2.88270712 2.88790584\n",
      " 2.89482307 2.99999976 3.0099833  3.0099833  3.0215888  3.05777693\n",
      " 3.074085   3.07571125 3.09354162 3.12569952 3.14642644 3.15277624\n",
      " 3.22800231 3.31209898 3.3451457  3.41174436 3.41613817 3.41613841\n",
      " 3.43511271 3.51994324 3.53128862 3.59165692 3.59583068 3.59722114\n",
      " 3.61662817 3.61801076 3.62767124 3.65786791 3.69999957 3.74966645]\n",
      "P:\n",
      "  (0, 58)\t1.1123856191126478e-48\n",
      "  (0, 63)\t1.629381818051472e-47\n",
      "  (0, 73)\t1.5443295993298925e-46\n",
      "  (0, 65)\t7.618908252567122e-46\n",
      "  (0, 87)\t1.2659956581135655e-45\n",
      "  (0, 51)\t1.361279451433849e-45\n",
      "  (0, 75)\t3.7587606280968164e-45\n",
      "  (0, 91)\t4.041633163961909e-45\n",
      "  (0, 106)\t5.024286834345004e-45\n",
      "  (0, 78)\t1.1373116778461108e-43\n",
      "  (0, 85)\t2.0320429640373955e-43\n",
      "  (0, 66)\t1.4684333760073635e-41\n",
      "  (0, 74)\t3.770849500982889e-41\n",
      "  (0, 55)\t3.7708940636562237e-41\n",
      "  (0, 84)\t4.687778032095442e-41\n",
      "  (0, 97)\t1.2268324422718476e-39\n",
      "  (0, 90)\t6.052593783026402e-39\n",
      "  (0, 61)\t3.2721531985417874e-37\n",
      "  (0, 94)\t1.0645757646313081e-35\n",
      "  (0, 62)\t1.4229865461859848e-35\n",
      "  (0, 96)\t3.654254097655959e-35\n",
      "  (0, 53)\t1.55931299641511e-34\n",
      "  (0, 71)\t3.463470407810223e-34\n",
      "  (0, 95)\t3.724106684873443e-34\n",
      "  (0, 99)\t7.692885885901127e-34\n",
      "  :\t:\n",
      "  (149, 66)\t7.330878315897751e-05\n",
      "  (149, 116)\t7.599730076727377e-05\n",
      "  (149, 78)\t7.033520848381596e-05\n",
      "  (149, 56)\t0.00010558619198568894\n",
      "  (149, 91)\t8.089484542949024e-05\n",
      "  (149, 110)\t0.00010514943370423587\n",
      "  (149, 146)\t0.00012319205315800593\n",
      "  (149, 137)\t0.00012026321604423454\n",
      "  (149, 103)\t0.00013056033586095764\n",
      "  (149, 114)\t0.00021544346852801004\n",
      "  (149, 147)\t0.0001061385506654824\n",
      "  (149, 111)\t0.00012617327534216203\n",
      "  (149, 63)\t0.00011659041473327155\n",
      "  (149, 113)\t0.0002226519553219883\n",
      "  (149, 133)\t0.00019368156378631995\n",
      "  (149, 123)\t0.00018253938249201694\n",
      "  (149, 126)\t0.0002449212382791976\n",
      "  (149, 121)\t0.0003351397451320423\n",
      "  (149, 83)\t0.0003792148904964361\n",
      "  (149, 70)\t0.0004211395245416383\n",
      "  (149, 142)\t0.0004301334718734168\n",
      "  (149, 101)\t0.0004301334718734168\n",
      "  (149, 138)\t0.0004307341317329757\n",
      "  (149, 127)\t0.00046861379804921465\n",
      "  (149, 149)\t0.00069446280453884\n",
      "\n",
      "knn_index:\n",
      "<__main__.Annoy object at 0x125ba7908>\n"
     ]
    }
   ],
   "source": [
    "affinities_train = MultiANNPerplexityBasedNN(\n",
    "    x,\n",
    "    perplexity=30,\n",
    "    method=\"annoy\",\n",
    "    metric=\"euclidean\",\n",
    "    n_jobs=8,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "#possible solution\n",
    "#affinities_train.knn_index = stelmach.build_knn_index()\n",
    "\n",
    "print(\"P:\")\n",
    "print(affinities_train.P)\n",
    "print(\"\")\n",
    "\n",
    "#print(\"data:\")\n",
    "#print(affinities_train.data)\n",
    "#print(\"\")\n",
    "\n",
    "print(\"knn_index:\")\n",
    "print(affinities_train.knn_index)\n",
    "\n",
    "#print(\".index\")\n",
    "#print(affinities_train.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "affinities_train = MultiANNPerplexityBasedNN(\n",
    "    x,\n",
    "    perplexity=30,\n",
    "    method=\"approx\",\n",
    "    metric=\"euclidean\",\n",
    "    n_jobs=8,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "#possible solution\n",
    "#affinities_train.knn_index = stelmach.build_knn_index()\n",
    "\n",
    "print(\"P:\")\n",
    "print(affinities_train.P)\n",
    "print(\"\")\n",
    "\n",
    "#print(\"data:\")\n",
    "#print(affinities_train.data)\n",
    "#print(\"\")\n",
    "\n",
    "print(\"knn_index:\")\n",
    "print(affinities_train.knn_index)\n",
    "\n",
    "#print(\".index\")\n",
    "#print(affinities_train.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Generate initial coordinates for our embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.52 ms, sys: 1.79 ms, total: 3.31 ms\n",
      "Wall time: 13.1 ms\n"
     ]
    }
   ],
   "source": [
    "%time init_train = initialization.pca(x_train, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Construct the `TSNEEmbedding` object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n",
      "Wall time: 11.2 µs\n",
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 7.15 µs\n"
     ]
    }
   ],
   "source": [
    "%time \n",
    "affinities_train = MultiANNPerplexityBasedNN(\n",
    "    x_train,\n",
    "    perplexity=30,\n",
    "    method=\"brute_force\",\n",
    "    metric=\"euclidean\",\n",
    "    n_jobs=8,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "\n",
    "%time\n",
    "\n",
    "embedding_train = TSNEEmbedding(\n",
    "    init_train,\n",
    "    affinities_train,\n",
    "    negative_gradient_method=\"fft\",\n",
    "    n_jobs=8,\n",
    "    callbacks=ErrorLogger(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Optimize embedding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Early exaggeration phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration   50, KL divergence  1.4010, 50 iterations in 1.6869 sec\n",
      "Iteration  100, KL divergence  1.1998, 50 iterations in 1.5971 sec\n",
      "Iteration  150, KL divergence  1.4183, 50 iterations in 1.4832 sec\n",
      "Iteration  200, KL divergence  1.3101, 50 iterations in 1.6733 sec\n",
      "Iteration  250, KL divergence  1.2498, 50 iterations in 1.8227 sec\n",
      "CPU times: user 8.02 s, sys: 148 ms, total: 8.17 s\n",
      "Wall time: 8.3 s\n"
     ]
    }
   ],
   "source": [
    "%time embedding_train_1 = embedding_train.optimize(n_iter=250, exaggeration=12, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "utils.plot(embedding_train_1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration   50, KL divergence  0.1884, 50 iterations in 1.4979 sec\n",
      "Iteration  100, KL divergence  0.0689, 50 iterations in 1.5214 sec\n",
      "Iteration  150, KL divergence  0.0551, 50 iterations in 1.5171 sec\n",
      "Iteration  200, KL divergence  0.0463, 50 iterations in 1.4401 sec\n",
      "Iteration  250, KL divergence  0.0322, 50 iterations in 1.4584 sec\n",
      "Iteration  300, KL divergence -0.0001, 50 iterations in 1.4480 sec\n",
      "Iteration  350, KL divergence -0.0038, 50 iterations in 1.4494 sec\n",
      "Iteration  400, KL divergence -0.0042, 50 iterations in 1.4542 sec\n",
      "Iteration  450, KL divergence -0.0038, 50 iterations in 1.4216 sec\n",
      "Iteration  500, KL divergence -0.0036, 50 iterations in 1.4409 sec\n",
      "Iteration  550, KL divergence -0.0047, 50 iterations in 1.4585 sec\n",
      "Iteration  600, KL divergence -0.0038, 50 iterations in 1.4145 sec\n",
      "Iteration  650, KL divergence -0.0046, 50 iterations in 1.4326 sec\n",
      "Iteration  700, KL divergence -0.0038, 50 iterations in 1.4286 sec\n",
      "Iteration  750, KL divergence -0.0039, 50 iterations in 1.4230 sec\n",
      "CPU times: user 21.3 s, sys: 324 ms, total: 21.6 s\n",
      "Wall time: 21.8 s\n"
     ]
    }
   ],
   "source": [
    "%time embedding_train_2 = embedding_train_1.optimize(n_iter=750, momentum=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils.plot(embedding_train_2, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/openTSNE/tsne.py\u001b[0m in \u001b[0;36mprepare_partial\u001b[0;34m(self, X, initialization, k, **affinity_params)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \"\"\"\n\u001b[1;32m    785\u001b[0m         P, neighbors, distances = self.affinities.to_new(\n\u001b[0;32m--> 786\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0maffinity_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m         )\n\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/openTSNE/affinity.py\u001b[0m in \u001b[0;36mto_new\u001b[0;34m(self, data, perplexity, return_distances)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mk_neighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_samples\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mperplexity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mneighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mknn_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         P = joint_probabilities_nn(\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embedding_test = embedding_train_2.prepare_partial(\n",
    "    x_test,\n",
    "    initialization=\"median\",\n",
    "    k=25,\n",
    "    perplexity=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-199-32e85df7f5e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'embedding_test' is not defined"
     ]
    }
   ],
   "source": [
    "utils.plot(embedding_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "embedding_test_1 = embedding_test.optimize(\n",
    "    n_iter=100,\n",
    "    learning_rate=1,\n",
    "    exaggeration=2,\n",
    "    momentum=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot(embedding_test_1, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Together\n",
    "\n",
    "We superimpose the transformed points onto the original embedding with larger opacity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "utils.plot(embedding_train_2, y_train, alpha=0.25, ax=ax)\n",
    "utils.plot(embedding_test_1, y_test, alpha=0.75, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test inheritance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Previous\n",
      "Init Base\n",
      "Init Super\n",
      "super bark\n"
     ]
    }
   ],
   "source": [
    "class base():\n",
    "    def __init__(self):\n",
    "        init = \"Init Base\"\n",
    "        print(init)\n",
    "    def berk(self):\n",
    "        #mood = \"happy\"\n",
    "        print(\"woof\")\n",
    "        \n",
    "#currently (full override):\n",
    "class over(base):\n",
    "    def __init__(self):\n",
    "        init = \"Init Previous\"\n",
    "        print(init)\n",
    "    def berk(self):\n",
    "        print(\"dog.bark(self)\")\n",
    "\n",
    "billo = over()  \n",
    "\n",
    "#with super:\n",
    "class sup(base):\n",
    "    def __init__(self):\n",
    "        super(sup, self).__init__()\n",
    "        init = \"Init Super\"\n",
    "        print(init)\n",
    "    def berk(self):\n",
    "        super(base, self)\n",
    "        print(\"super bark\")\n",
    "        #print(mood)\n",
    "\n",
    "bello = sup()\n",
    "bello.berk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"x.shape: {}\".format(x.shape))\n",
    "arr = np.empty(x.shape)\n",
    "#print(\"arr: {}\".format(arr))\n",
    "entry = [0,1,2,3]\n",
    "arr[0] = entry\n",
    "print(\"arr + entry {}\".format(arr[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#index = neighbors, distances\n",
    "data = [[[0,1,2,3],[0,20,30,40]],[[1,1,2,3],[10,20,30,40]],[[2,1,2,3],[20,20,30,40]],\n",
    "[[3,1,2,3],[30,20,30,40]],[[4,1,2,3],[40,20,30,40]]]\n",
    "\n",
    "neighbors = np.empty((5,4))\n",
    "distances = np.empty((5,4))\n",
    "\n",
    "for i in range(len(data)):\n",
    "    #neighbors_single, distances_single = np.asarray(data[i])\n",
    "    neighbors[i], distances[i] = np.asarray(data[i])\n",
    "#    neighbors[i] = neighbors_single\n",
    "#    distances[i] = distances_single\n",
    "      \n",
    "print(neighbors)\n",
    "print(distances)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#indexarr = np.asarray(indexlist)\n",
    "#np.append(indexarr[1],np.asarray(indexlist1)[1], axis=0)\n",
    "#neig, dist = indexarr[1]\n",
    "#np.append(indexarr[0],np.asarray(indexlist1)[1], axis=0)\n",
    "\n",
    "#print(indexarr)\n",
    "\n",
    "\n",
    "#neigh = np.empty((4,4))\n",
    "#dist = np.empty\n",
    "\n",
    "#empty[0] = indexarr[0]\n",
    "#print(\"\")\n",
    "#print(empty)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test difference range, enumerate for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = [[1,2,3],[4,5,6]]\n",
    "     \n",
    "#for i,x in enumerate(X):\n",
    "#    print(i,x)\n",
    "    \n",
    "#n_items, vector_length = x.shape\n",
    "#for i, j in range(n_items):\n",
    "#    print(j[i], i)\n",
    "#print(\"\")\n",
    "#for i,j in enumerate(x):\n",
    "#    print(i,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test ngtpy install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ngtpy.cpython-37m-darwin.so, 2): Library not loaded: /usr/local/opt/gcc/lib/gcc/8/libgomp.1.dylib\n  Referenced from: /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ngtpy.cpython-37m-darwin.so\n  Reason: image not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-4e3b596bd14d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mngtpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mobjects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ngtpy.cpython-37m-darwin.so, 2): Library not loaded: /usr/local/opt/gcc/lib/gcc/8/libgomp.1.dylib\n  Referenced from: /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ngtpy.cpython-37m-darwin.so\n  Reason: image not found"
     ]
    }
   ],
   "source": [
    "import ngtpy\n",
    "import random\n",
    "\n",
    "dim = 10\n",
    "objects = []\n",
    "for i in range(0, 100) :\n",
    "    vector = random.sample(range(100), dim)\n",
    "    objects.append(vector)\n",
    "\n",
    "query = objects[0]\n",
    "\n",
    "ngtpy.create(b\"tmp\", dim)\n",
    "index = ngtpy.Index(b\"tmp\")\n",
    "index.batch_insert(objects)\n",
    "index.save()\n",
    "\n",
    "result = index.search(query, 3)\n",
    "\n",
    "for i, o in enumerate(result) :\n",
    "    print(str(i) + \": \" + str(o[0]) + \", \" + str(o[1]))\n",
    "    object = index.get_object(o[0])\n",
    "    print(object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### assign object with argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__\n",
      "12\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "class base():\n",
    "    def __init__(self):\n",
    "        print(\"__\")\n",
    "\n",
    "class over():\n",
    "    def __init__(self, var):\n",
    "        print(var)\n",
    "    \n",
    "dog = base()\n",
    "deg = over(12)\n",
    "\n",
    "class DummyANN(KNNIndex):\n",
    "    def __init__(self, var):\n",
    "        self.var = var\n",
    "        print(self.var)\n",
    "        \n",
    "dum = DummyANN(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test TSNE manifold: change only single class function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has to appear\n",
      "20\n",
      "Has to appear\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "class original():\n",
    "    def __init__(self, var):\n",
    "        self.var = var\n",
    "        print(\"Has to appear\")\n",
    "        \n",
    "    def fit(self):\n",
    "        print(self.var+self.var)\n",
    "\n",
    "class mine(original):\n",
    "    def fit(self):\n",
    "        print(self.var)\n",
    "    \n",
    "previous = original(10)\n",
    "previous.fit()\n",
    "\n",
    "now = mine(10)\n",
    "now.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MutliScale(MyMultiscalemixture): Check if overwriting a class with a new method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Volumes/ProjectDrive/code/python/bakk-project/multi-ann-tsne-widget',\n",
       " '/Library/Frameworks/Python.framework/Versions/3.7/lib/python37.zip',\n",
       " '/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7',\n",
       " '/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload',\n",
       " '',\n",
       " '/Users/make/Library/Python/3.7/lib/python/site-packages',\n",
       " '/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages',\n",
       " '/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/Users/make/.ipython']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
